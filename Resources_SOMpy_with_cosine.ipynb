{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Content\n",
        "\n",
        "1. Load the cohere wikipedia dataset\n",
        "2. Extract the cohere embeddings for 1000 documents with 768 dimensions\n",
        "3. Select parameters for the SOM by comparing quantization errors\n",
        "4. Train the SOM on the wikipedia document embeddings\n",
        "5. Select the BMUs with at least 1 hit\n",
        "6. Get query\n",
        "7. Embed query into the same dimensions (768)\n",
        "8. Normalize the query vector with the same normalization (var) applied on wikipedia embedding during it's training. (only var normalization has been implemented and available in the SOM library)\n",
        "9. Select the BMU for the query embedding using cosine similarity search (cosine on exp : (1,768) and (89,768))\n",
        "10. Get all embeddings allocated to that BMU as candidate context embeddings\n",
        "11. Get the cosine similarities between the candidate embeddings and the query embedding to select the top k=5 context embeddings. ( exp : (1,768) and (13,768))\n",
        "12. Get the cosine similarity between all document embeddings and the query embedding to select the top k=5 context embeddings. ( exp : (1,768) and (1000,768))\n",
        "13. COMPARE 11 and 12 contexts in terms of\n",
        "*   Accuracy\n",
        "*   Relavance\n",
        "*   Speed of retrieval\n",
        "*   Efficiency of retrieval etc.\n",
        "\n"
      ],
      "metadata": {
        "id": "Cs67_R-4_u1U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GmuTcnWUipLe",
        "outputId": "ae2589d7-bee9-40ee-e0f1-737a9f1344cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\n",
            "Collecting cohere\n",
            "  Downloading cohere-5.15.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.14.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.67)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere)\n",
            "  Downloading fastavro-1.11.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.28.1)\n",
            "Collecting httpx-sse==0.4.0 (from cohere)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.33.2)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.21.2)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere)\n",
            "  Downloading types_requests-2.32.4.20250611-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.16.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (24.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<1,>=0.15->cohere) (0.33.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2025.3.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (1.1.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.3.1)\n",
            "Downloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cohere-5.15.0-py3-none-any.whl (259 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading fastavro-1.11.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.4.20250611-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: types-requests, python-docx, PyMuPDF, httpx-sse, fastavro, cohere\n",
            "Successfully installed PyMuPDF-1.26.3 cohere-5.15.0 fastavro-1.11.1 httpx-sse-0.4.0 python-docx-1.2.0 types-requests-2.32.4.20250611\n"
          ]
        }
      ],
      "source": [
        "!pip install python-docx PyMuPDF pandas tiktoken langchain cohere"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fsspec==2023.9.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Qj-avPiq3l7",
        "outputId": "7079d375-1213-4285-b1d1-f7902498b9f9",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fsspec==2023.9.2\n",
            "  Downloading fsspec-2023.9.2-py3-none-any.whl.metadata (6.7 kB)\n",
            "Downloading fsspec-2023.9.2-py3-none-any.whl (173 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/173.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.4/173.4 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fsspec\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2023.9.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fsspec-2023.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ETn166NWaIZO",
        "outputId": "5136ea2e-f973-4c18-ffc8-e2a3148b03bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2023.9.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.6.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: datasets\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.14.4\n",
            "    Uninstalling datasets-2.14.4:\n",
            "      Successfully uninstalled datasets-2.14.4\n",
            "Successfully installed datasets-3.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9rLtxUDs09k7",
        "outputId": "77c67008-7074-4ef8-a46b-02a05dcc4c53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/GayuniBas2001/SOMPY_sevamoo.git\n",
            "  Cloning https://github.com/GayuniBas2001/SOMPY_sevamoo.git to /tmp/pip-req-build-9qd9ov9o\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/GayuniBas2001/SOMPY_sevamoo.git /tmp/pip-req-build-9qd9ov9o\n",
            "  Resolved https://github.com/GayuniBas2001/SOMPY_sevamoo.git to commit 420bec153a6600857d2160dd1955b2e0f15f799a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.11/dist-packages (from SOMPY==1.1.1) (2.0.2)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.11/dist-packages (from SOMPY==1.1.1) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.11/dist-packages (from SOMPY==1.1.1) (1.6.1)\n",
            "Requirement already satisfied: numexpr>=2.5 in /usr/local/lib/python3.11/dist-packages (from SOMPY==1.1.1) (2.11.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21->SOMPY==1.1.1) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21->SOMPY==1.1.1) (3.6.0)\n",
            "Building wheels for collected packages: SOMPY\n",
            "  Building wheel for SOMPY (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for SOMPY: filename=SOMPY-1.1.1-py3-none-any.whl size=29301 sha256=31a5e052175d321c199d5243921bf9967cd8693e3b74416255c013eafdbccff5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xs7_hkz7/wheels/fc/dd/d6/26375a31b7c69ce2502112a68ead58548f7caa4102897a065d\n",
            "Successfully built SOMPY\n",
            "Installing collected packages: SOMPY\n",
            "Successfully installed SOMPY-1.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip3 install --upgrade git+https://github.com/GayuniBas2001/SOMPY_sevamoo.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUqWdwABiYlA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import io\n",
        "import re\n",
        "import base64\n",
        "import logging\n",
        "import fitz\n",
        "import docx\n",
        "import tiktoken\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import numpy as np\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEz3seM-X5GH"
      },
      "outputs": [],
      "source": [
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 01. Loading Wikipedia cohere embeddings"
      ],
      "metadata": {
        "id": "Ti63b3NYaCfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "#Load at max 1000 documents + embeddings\n",
        "max_docs = 1000\n",
        "docs_stream = load_dataset(f\"Cohere/wikipedia-22-12-simple-embeddings\", split=\"train\", streaming=True)"
      ],
      "metadata": {
        "id": "PU8P4hkPabzz",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190,
          "referenced_widgets": [
            "5e18b491becd444083204cd619f1cbf1",
            "b33f3d912c0247c1b30ee40ae68122f2",
            "324bacceff6b43be9ad9c5582eac6739",
            "f158c59b125d422484ea4468307aeaca",
            "359a69cdaabb4744a2defa92d0d2895d",
            "42a71aeaae2d416195ea6a47684a2f27",
            "668c85698024412497c3ab2bc6219695",
            "d92f27ed9d3e4f1998ef4224f3ee43d8",
            "3b17c655ffea47e88555dc1cb2d4659d",
            "59668f7702194cdf912b53ada5ce0832",
            "562a90eaaa0c468cbe2048d224b378fb",
            "ce48574361554d4f9d5af13c79cd2860",
            "66284b979f8645bca3e948bc85e069c6",
            "9a4347855f254ea1b4229a4707d3c5fb",
            "0f539af298d549d996fa74fc34b646dc",
            "b960ab39aeb741cda49774271a128924",
            "a727a6fcb75b4fcdb0a96ba30156d527",
            "ece8e766ec2845c4a4e03d138dd3c6c9",
            "08c4b69f2af54a1884ecb539b5635e5d",
            "322bbda86eb64cc5901a3ce48151613e",
            "d8cf16c34589428798f7e291c7b0eac8",
            "06fd12487c634d5b9fc2ba5d53c845bf"
          ]
        },
        "outputId": "9e8051d8-8033-4057-d772-f3e969ab6e1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e18b491becd444083204cd619f1cbf1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "dataset_infos.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce48574361554d4f9d5af13c79cd2860"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs_stream"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TifuALR6bAEk",
        "outputId": "70690575-2b9a-434c-88c0-8120f1eec982",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IterableDataset({\n",
              "    features: ['id', 'title', 'text', 'url', 'wiki_id', 'views', 'paragraph_id', 'langs', 'emb'],\n",
              "    num_shards: 4\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "docs = []\n",
        "wik_embeddings = []\n",
        "\n",
        "for doc in docs_stream:\n",
        "    docs.append(doc)\n",
        "    wik_embeddings.append(doc['emb'])\n",
        "    if len(docs) >= max_docs:\n",
        "        break\n",
        "\n",
        "wik_embeddings = torch.tensor(wik_embeddings)"
      ],
      "metadata": {
        "id": "ARgRAD1BbMRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wik_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0VVIvDTbV6F",
        "outputId": "39a3b744-6981-4955-f09b-e40d6477f252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1000, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7Jxx3GM09ca"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "np_embeddings = np.array(wik_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 02. Query Embedding"
      ],
      "metadata": {
        "id": "oLxmFmyo6RFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cohere\n",
        "from getpass import getpass\n",
        "\n",
        "# Ask the user to enter their Cohere API key\n",
        "cohere_api_key = getpass(\"Enter your Cohere API key: \")\n",
        "\n",
        "co = cohere.ClientV2(api_key=cohere_api_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-b5ItjsdIIr",
        "outputId": "ba2fc778-120e-497b-a49f-a47f51797522"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Cohere API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use cohere API key : KMgAyxtG2SjcOkLRvGJpS0ZIYk34RCEKtjs5AMPp"
      ],
      "metadata": {
        "id": "eHeVMS3Gc2hN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"multilingual-22-12\" # To get 768 dimensions like in the wikipedia embeddings, we must use this model for the query\n",
        "input_type = \"search_query\"\n",
        "output_dimension = wik_embeddings.shape[1]\n",
        "\n",
        "def embed_prompt(prompt: list,\n",
        "                 model: str = 'multilingual-22-12',\n",
        "                 input_type: str = 'search_query',\n",
        "                 output_dimenion: int = wik_embeddings.shape[1]) -> np.ndarray:\n",
        "\n",
        "    texts = prompt  # Ensure prompt is a list, as co.embed expects a list of texts\n",
        "\n",
        "    res = co.embed(\n",
        "        texts=texts,\n",
        "        model=model,\n",
        "        input_type=input_type,\n",
        "        output_dimension=output_dimension, # Specify the output dimension\n",
        "        embedding_types=[\"float\"],\n",
        "    )\n",
        "\n",
        "    if res.embeddings and res.embeddings.float:\n",
        "        return np.array(res.embeddings.float) # co.embed returns a list of embeddings, one for each text in the input list. If we provide only one prompt, we take the first embedding\n",
        "    else:\n",
        "        raise ValueError(\"Cohere embed API did not return expected embeddings.\")"
      ],
      "metadata": {
        "id": "rLCNM7Dq6QTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULWSuo92WBvW"
      },
      "outputs": [],
      "source": [
        "questions = [\n",
        "    \"What is the international standard that uses the 24-hour clock format?\",\n",
        "    \"Which three parts make up the Tanakh in Judaism?\",\n",
        "    \"In which three cities was Gotham City filmed for The Dark Knight Rises?\",\n",
        "    \"Against which team did Ronaldo score his famous bicycle-kick goal in the 2018 UEFA Champions League?\",\n",
        "    \"Which German state’s court ruled on 5 April 2018 that Puigdemont would not be extradited on charges of rebellion?\",\n",
        "    \"What is the voltage range typically used to represent the On state in a logic gate?\",\n",
        "    \"Where is Canada's national capital, where the federal government meets?\",\n",
        "    \"According to the Copenhagen Interpretation, what state is the cat in before the box is opened?\",\n",
        "    \"What gas is identified as the main cause of global warming due to burning fossil fuels?\",\n",
        "    \"Which Indian leader used peaceful tactics including \\\"ahimsa\\\" to lead the freedom movement against British rule?\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_query_embeddings = embed_prompt(questions)\n",
        "original_query_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlF1l9e5mNf8",
        "outputId": "260d1873-b955-4843-8b1e-3162a5a4fee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "id": "W8hgcrDOdK0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lr6e5gezq3g"
      },
      "source": [
        "# 03. Context Retreival from Reduced Dimensions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from math import sqrt\n",
        "from sompy.sompy import SOMFactory, SOM\n",
        "import itertools\n",
        "from typing import Any, Dict, List, Tuple\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "#cal_quantization_error function is not used in the code. This is to understand how SOM is calculating the qe\n",
        "def cal_quantization_error(sm: SOM, data: np.ndarray) -> float:\n",
        "    bmus, squared_partial = sm.find_bmu(data)\n",
        "    fixed_euclidean_x2 = np.einsum('ij,ij->i', data, data)\n",
        "    distances = np.sqrt(squared_partial + fixed_euclidean_x2)\n",
        "    return np.mean(distances)\n",
        "\n",
        "def train_som_model(np_embeddings, mapsizes, normalizations, initializations, lattices, neighborhoods, trainings, names, rough_len, finetune_len):\n",
        "    som_fac = SOMFactory()\n",
        "    sm = som_fac.build(np_embeddings, mapsize=mapsizes, normalization=normalizations, initialization=initializations, lattice=lattices, neighborhood=neighborhoods, training=trainings, name=names)\n",
        "    sm.train(n_job=1, verbose=False, train_rough_len=rough_len, train_finetune_len=finetune_len)\n",
        "    topographic_error = sm.calculate_topographic_error()\n",
        "    quantization_error = sm.quant_error_history[-1]\n",
        "    logger.info(f\"Topographic error = {topographic_error}; Quantization error = {quantization_error}\")\n",
        "    return sm\n",
        "\n",
        "def find_closest_hit_per_bmu(sm):\n",
        "    chunk_bmu_indices = sm._bmu[0].astype(int)\n",
        "    chunk_bmu_qe = sm._bmu[1] #qe between the chunk and it's bmu\n",
        "    data = sm._data #the chunk embeddings (already normalized)\n",
        "\n",
        "    closest_indices = np.full(sm.codebook.nnodes, np.nan)\n",
        "    min_errors = np.full(sm.codebook.nnodes, np.inf)\n",
        "\n",
        "    for idx, (bmu, err) in enumerate(zip(chunk_bmu_indices, chunk_bmu_qe)):\n",
        "        if err < min_errors[bmu]:\n",
        "            min_errors[bmu] = err\n",
        "            closest_indices[bmu] = idx\n",
        "\n",
        "    bmu_first_hit_vectors = [data[int(i)] if not np.isnan(i) else None for i in closest_indices]\n",
        "    return closest_indices, bmu_first_hit_vectors\n",
        "\n",
        "def cosine_bmu_retrieve(normed_query_embedding, som_model, bmu_hit_vectors_with_indices, top_k: int = 5): #Here we take 5 best matiching BMUs (units with at least 1 hit) for a query\n",
        "    filtered = [(i, v) for i, v in bmu_hit_vectors_with_indices if v is not None and not np.isnan(v).any()]\n",
        "    if len(filtered) == 0:\n",
        "        raise ValueError(\"No valid BMU vectors available for similarity comparison.\")\n",
        "\n",
        "    indices, vectors = zip(*filtered)\n",
        "    vectors = np.array(vectors)\n",
        "    indices = np.array(indices)\n",
        "    print('number of hit vectors: ',len(indices))\n",
        "\n",
        "    similarities = cosine_similarity(normed_query_embedding, vectors)\n",
        "    sorted_indices_desc = np.argsort(similarities[0])[::-1]\n",
        "    top_k_indices = sorted_indices_desc[:top_k] #Indices from the similarity array\n",
        "    print(f\"top_k_indices : {top_k_indices}\")\n",
        "    selected_bmu_index = indices[top_k_indices] #Indices of the actual BMUs\n",
        "    print(f\"selected_bmu_index : {selected_bmu_index}\")\n",
        "    return selected_bmu_index\n",
        "\n",
        "def cosine_context_similarity(normed_query_embedding, candidate_vectors_with_indices, top_k: int = 5):\n",
        "    indices, vectors = zip(*candidate_vectors_with_indices)\n",
        "    vectors = np.array(vectors)\n",
        "    logger.info(f\"vectors shape : {vectors.shape}\") #(cand_count,768)\n",
        "    indices = np.array(indices)\n",
        "    logger.info(f\"indices shape : {indices.shape}\") #(cand_count,)\n",
        "    logger.info(f\"normed_query_embedding shape : {normed_query_embedding.shape}\") #(1,768)\n",
        "    similarities = cosine_similarity(normed_query_embedding, vectors)\n",
        "    logger.info(f\"similarities shape : {similarities.shape}\") #(1, valid)\n",
        "    return similarities\n",
        "\n",
        "def normalize_reshape (query_embedding, sm):\n",
        "    vec = query_embedding.reshape(1, -1)\n",
        "    normed_query_embedding = sm._normalizer.normalize_by(sm.data_raw, vec)\n",
        "    logger.info(f\"new shape : \",vec.shape)\n",
        "    return normed_query_embedding\n",
        "\n",
        "def get_som_context(\n",
        "    query_embedding: np.ndarray,\n",
        "    som_model,\n",
        "    bmu_hit_vectors_with_indices,\n",
        "    chunks,\n",
        "    rerank_method: str = 'cosine',\n",
        "    top_k: int = 5,\n",
        "    bmu_k: int = 5\n",
        "):\n",
        "  q_vec = normalize_reshape(query_embedding, som_model)\n",
        "  logger.info(f\"q_vec shape : \",q_vec.shape)\n",
        "  q_bmus = cosine_bmu_retrieve(q_vec, som_model, bmu_hit_vectors_with_indices, bmu_k)\n",
        "  logger.info(f\"q_bmus to use : \",q_bmus)\n",
        "\n",
        "  chunk_bmu_indices = som_model._bmu[0].astype(int)\n",
        "\n",
        "  q_bmus_set = set(q_bmus)\n",
        "  candidates_emb = [(i, chunks[i]['emb']) for i, bmu_index in enumerate(chunk_bmu_indices) if bmu_index in q_bmus_set]\n",
        "\n",
        "  logger.info(f\"Found {len(candidates_emb)} candidates\")\n",
        "\n",
        "  # d) Rerank based on the specified method\n",
        "  if rerank_method == 'cosine':\n",
        "      scores = cosine_context_similarity(q_vec, candidates_emb, top_k)[0]\n",
        "      sorted_indices_desc = np.argsort(scores)[::-1] # indices of 20 candidates, not the actual indices\n",
        "\n",
        "      top_k_chunk_indices = [candidates_emb[i][0] for i in sorted_indices_desc[:top_k]]\n",
        "\n",
        "      logger.info('top_k_chunk_indices : ', top_k_chunk_indices)\n",
        "\n",
        "      top_k_indices = top_k_chunk_indices\n",
        "\n",
        "      context = [chunks[i]['text'] for i in top_k_indices]\n",
        "      context_scores = scores[sorted_indices_desc[:top_k]]\n",
        "\n",
        "      return context, context_scores\n",
        "\n",
        "  else:\n",
        "      raise ValueError(f\"Unknown rerank_method: {rerank_method}. Choose 'cosine' or 'quantization_error'.\")"
      ],
      "metadata": {
        "id": "PVEi_UxBxnyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqXFNxQVOPdq"
      },
      "outputs": [],
      "source": [
        "results = [{'mapsize': (10, 10), 'normalization': 'var', 'initialization': 'random', 'lattice': 'hexa', 'neighborhood': 'gaussian', 'training': 'batch', 'name': 'som1', 'rough_len': 800, 'finetune_len': 100, 'test_index': 0, 'topographic_error': np.float64(0.092), 'quantization_error': np.float64(24.17343805953296)}, {'mapsize': (10, 10), 'normalization': 'var', 'initialization': 'random', 'lattice': 'hexa', 'neighborhood': 'gaussian', 'training': 'seq', 'name': 'som1', 'rough_len': 800, 'finetune_len': 100, 'test_index': 1, 'topographic_error': np.float64(0.147), 'quantization_error': np.float64(23.95357177963876)}, {'mapsize': (10, 10), 'normalization': 'var', 'initialization': 'random', 'lattice': 'rect', 'neighborhood': 'gaussian', 'training': 'batch', 'name': 'som1', 'rough_len': 800, 'finetune_len': 100, 'test_index': 2, 'topographic_error': np.float64(0.399), 'quantization_error': np.float64(23.053306262876312)}, {'mapsize': (10, 10), 'normalization': 'var', 'initialization': 'random', 'lattice': 'rect', 'neighborhood': 'gaussian', 'training': 'seq', 'name': 'som1', 'rough_len': 800, 'finetune_len': 100, 'test_index': 3, 'topographic_error': np.float64(0.423), 'quantization_error': np.float64(23.07128526327146)}, {'mapsize': (10, 10), 'normalization': 'var', 'initialization': 'pca', 'lattice': 'hexa', 'neighborhood': 'gaussian', 'training': 'batch', 'name': 'som1', 'rough_len': 800, 'finetune_len': 100, 'test_index': 4, 'topographic_error': np.float64(0.119), 'quantization_error': np.float64(23.89813955987797)}, {'mapsize': (10, 10), 'normalization': 'var', 'initialization': 'pca', 'lattice': 'hexa', 'neighborhood': 'gaussian', 'training': 'seq', 'name': 'som1', 'rough_len': 800, 'finetune_len': 100, 'test_index': 5, 'topographic_error': np.float64(0.119), 'quantization_error': np.float64(23.89813955987797)}, {'mapsize': (10, 10), 'normalization': 'var', 'initialization': 'pca', 'lattice': 'rect', 'neighborhood': 'gaussian', 'training': 'batch', 'name': 'som1', 'rough_len': 800, 'finetune_len': 100, 'test_index': 6, 'topographic_error': np.float64(0.404), 'quantization_error': np.float64(23.062587304824785)}, {'mapsize': (10, 10), 'normalization': 'var', 'initialization': 'pca', 'lattice': 'rect', 'neighborhood': 'gaussian', 'training': 'seq', 'name': 'som1', 'rough_len': 800, 'finetune_len': 100, 'test_index': 7, 'topographic_error': np.float64(0.404), 'quantization_error': np.float64(23.062587304824785)}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rOpUiwjotdQ"
      },
      "outputs": [],
      "source": [
        "test_index = 2\n",
        "test_case = results[test_index]\n",
        "\n",
        "def reduced_dim_retreival(\n",
        "    np_embeddings,\n",
        "    original_query_embeddings,\n",
        "    test_case,\n",
        "    sm\n",
        "):\n",
        "  som_contexts_scores = []\n",
        "  map_size = sm.codebook.nnodes\n",
        "\n",
        "  bmu_first_hit_indices, bmu_first_hit_vectors = find_closest_hit_per_bmu(sm) #index of the first hit chunk and it's vector\n",
        "\n",
        "  bmu_hit_vectors_with_indices = [(i, v) for i,v in enumerate(bmu_first_hit_vectors)] #idex of the bmu (to represent the cluster) and the vector of the chunk\n",
        "\n",
        "  for q in original_query_embeddings:\n",
        "    print('q shape', q.shape)\n",
        "    som_context, som_context_score = get_som_context(q, sm, bmu_hit_vectors_with_indices, docs)\n",
        "    som_contexts_scores.append((som_context, som_context_score))\n",
        "\n",
        "  return som_contexts_scores"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sm = train_som_model(\n",
        "        np_embeddings,\n",
        "        test_case['mapsize'],\n",
        "        test_case['normalization'],\n",
        "        test_case['initialization'],\n",
        "        test_case['lattice'],\n",
        "        test_case['neighborhood'],\n",
        "        test_case['training'],\n",
        "        test_case['name'],\n",
        "        test_case['rough_len'],\n",
        "        test_case['finetune_len']\n",
        "  )"
      ],
      "metadata": {
        "id": "lZpf4tsOq66w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "som_contexts_scores = reduced_dim_retreival(np_embeddings, original_query_embeddings, test_case, sm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Bwhi2Wd6Kq9",
        "outputId": "4d507339-79ad-4213-aeda-470d9a993bda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of hit vectors:  88\n",
            "top_k_indices : [86 47 12  1 55]\n",
            "selected_bmu_index : [98 52 12  1 61]\n",
            "number of hit vectors:  88\n",
            "top_k_indices : [11 68  3 67 38]\n",
            "selected_bmu_index : [11 76  3 74 42]\n",
            "number of hit vectors:  88\n",
            "top_k_indices : [54 55 86 73 67]\n",
            "selected_bmu_index : [60 61 98 82 74]\n",
            "number of hit vectors:  88\n",
            "top_k_indices : [79 72 54 80 64]\n",
            "selected_bmu_index : [90 80 60 91 70]\n",
            "number of hit vectors:  88\n",
            "top_k_indices : [54 72 63 44 86]\n",
            "selected_bmu_index : [60 80 69 49 98]\n",
            "number of hit vectors:  88\n",
            "top_k_indices : [10 47 19  1 56]\n",
            "selected_bmu_index : [10 52 20  1 62]\n",
            "number of hit vectors:  88\n",
            "top_k_indices : [34 33 44 25 86]\n",
            "selected_bmu_index : [38 37 49 27 98]\n",
            "number of hit vectors:  88\n",
            "top_k_indices : [54 26 55 86 10]\n",
            "selected_bmu_index : [60 28 61 98 10]\n",
            "number of hit vectors:  88\n",
            "top_k_indices : [15 86 16  6 55]\n",
            "selected_bmu_index : [16 98 17  6 61]\n",
            "number of hit vectors:  88\n",
            "top_k_indices : [74 64 73 59 44]\n",
            "selected_bmu_index : [83 70 82 65 49]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for r in som_contexts_scores:\n",
        "  # print(f\"[{r[1]:.3f}]\\t{r[0]}\")\n",
        "  for txt, score in zip(r[0],r[1]):\n",
        "    print(f\"[{score:.3f}]\\t{txt}\")\n",
        "  print('\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoooLN948d-K",
        "outputId": "0eefcb69-d25e-490e-fdc5-4fa161e28e7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.100]\t\"Within one hour, one of the atoms of the radioactive material might decay (or break down because the material is not stable), or it may not. \"\n",
            "[0.087]\tThe question now is: at the end of the hour, is the cat alive or dead? Schrödinger says that according to the Copenhagen Interpretation, as long as the door is closed, the cat is dead and alive. There is no way to know until the door is opened. But by opening the door, the person is interfering with the experiment. The person and the experiment have to be described with reference to each other.\n",
            "[0.081]\t\"A Geiger counter which counts the amount of radioactive decay and a little bit of a radioactive element are in the room. \"\n",
            "[0.046]\tMagnotta was previously sought by animal rights groups for allegedly uploading videos of himself killing kittens. There was no accusation for these videos.\n",
            "[0.045]\tTraffic lights change their colors in the same order every time. In most English-speaking countries, traffic lights usually change in this order:\n",
            "\n",
            "\n",
            "\n",
            "[0.119]\tTertullian was probably the first person to call these books the \"Old Testament.\" He used the Latin name \"vetus testamentum\" in the 2nd century.\n",
            "[0.119]\tIn 1999, Nunavut was created as Canada's third territory, out of the eastern Northwest Territories, in an agreement with the Inuit people.\n",
            "[0.115]\tIn the Old Testament, Almighty God is the one who created the world. The God of the Old Testament is not always presented as the only God who exists Even though there may be other gods, the God of the Old Testament is always shown as the only God whom Israel is to worship. The God of the Old Testament is the one \"true God\"; only Yahweh is Almighty. Both Jews and Christians have always interpreted the Bible (both the \"Old\" and \"New\" Testaments) as an affirmation of the oneness of Almighty God.\n",
            "[0.090]\tParagraphs may signal when the writer changes topics. Each paragraph may have a number of sentences, depending on the topic.\n",
            "[0.081]\tIn humans, sexual intercourse seems to serve three types of purposes, which do not exclude one another:\n",
            "\n",
            "\n",
            "\n",
            "[0.208]\tAll cast and crew members worked on all three movies, except for music composer James Newton Howard who did not work on \"The Dark Knight Rises\". Composer Hans Zimmer worked together with Howard on the first two films and made the soundtrack for the last movie by himself. Katie Holmes played Rachel Dawes in \"Batman Begins\", but was replaced by Maggie Gyllenhaal in \"The Dark Knight\". Liam Neeson appeared as Ra's al Ghul in \"Batman Begins\" and in \"The Dark Knight Rises\".\n",
            "[0.124]\tHeath Ledger received an Academy Award for Best Supporting Actor for his role as The Joker in \"The Dark Knight.\" Ledger died before the movie was released and the award was given posthumously.\n",
            "[0.056]\tKendra Lust (born September 18, 1978 in Madison Heights, Michigan) is an American pornographic actress.\n",
            "[0.054]\tIn the 2014 movie, \"\", each of the Kingsman agents is named after one of the knights of the Round Table. Gary \"Eggsy\" Unwin, the main character, has the code name 'Galahad'. This is also the code name of Harry Hart, Eggsy's mentor. Roxy Morton, the only female Kingsman, has the codename 'Lancelot'. 'Arthur' is the codename for the leader of Kingsman, while 'Merlin' is the codename for their trainer and tech coordinator.\n",
            "[0.052]\tOn July 11, Lin's body was cremated and his ashes were buried in the Notre-Dame-des-Neiges cemetery in Montreal.\n",
            "\n",
            "\n",
            "\n",
            "[0.270]\tOn 18 April 2017, he became the first player to reach 100 goals in the UEFA Champions League, after he scored a hat-trick in a 4-2 extra-time win against Bayern Munich. On 18 March 2018, Ronaldo reached his 50th career hat-trick in a 6-3 win against Girona. Ronaldo scored an amazing bicycle-kick in a UEFA Champions League match against Juventus on 3 April 2018. He got a standing ovation, or round of applause, from the Juventus fans after scoring that goal. Real Madrid went on to play the final against Liverpool F.C.. Real Madrid became champions, so that was Ronaldo's 5th Champions League.\n",
            "[0.191]\tOn 2 November 2011, Ronaldo scored both goals in a 2-0 Champions League group stage win against Olympique Lyon. The second goal was his 100th goal for Real Madrid. He achieved this in just 105 matches. He scored his 100th La Liga goal for his club in just 92 appearances in a 5-1 win against Real Sociedad on 24 March 2012.\n",
            "[0.186]\tHe scored his first goals for the club on 16 September against US Sassuolo. Juventus won 2-1 at home. Three days later, on 19 September, he was controversially sent off against Valencia C.F. for \"violent behavior\". He was crying as he received the red card and said he \"did nothing\". Ronaldo won his first trophy with the club, the 2018 Supercoppa Italiana, in January 2019. In the match, he scored the only goal from a header against AC Milan.\n",
            "[0.186]\tIn the 2007-08 season, Ronaldo scored his first and only hat-trick for Manchester United in a 6–0 win against Newcastle United on 12 January 2008. In the 2008 Champions League final against Chelsea, he scored a header as the match ended 1-1 after extra time. Although he missed his penalty, Manchester United won the shootout 6-5 and Ronaldo won his first UEFA Champions League. On 15 November 2008, Ronaldo scored his 100th goal for United in a 5-0 win against Stoke City. He also scored two free-kicks: the first one was his 100th goal. He scored a total of 42 goals and won the European Golden Boot, an award given to the top scorer of every European national league.\n",
            "[0.183]\tIn the 2013-14 season, Ronaldo broke the record for most goals in one Champions League season by scoring his 17th goal with a penalty in extra time in the final against Atlético Madrid that Real Madrid won 4–1. The previous record was 14 goals, set by Messi in the 2011-12 season.\n",
            "\n",
            "\n",
            "\n",
            "[0.334]\tOn 25 March 2018, while returning to Brussels from a trip to Finland, Puigdemont was stopped near the Danish border with Germany and arrested pursuant to the European warrant that had been reissued against him two days previously. On 5 April 2018, the Oberlandesgericht in the German state of Schleswig-Holstein ruled that Puigdemont would not be extradited on the charges of rebellion, and released him on bail.\n",
            "[0.241]\tOn 2 November, Spanish courts issued an European Arrest Warrant against Puigdemont and four other cabinet members to Belgian authorities. Two days later, they turned themselves in to the Belgian police. Hours later, he was released.\n",
            "[0.236]\tOn 30 October 2017, Puigdemont fled to Belgium in a move to avoid action from the Spanish judiciary. A month later, he was re-elected to the Parliament.\n",
            "[0.168]\tHis status as President is a matter of dispute following Catalonia's declaration of independence from Spain on 27 October 2017. From the perspective of the Government of Catalonia, he remains Catalan President. From the perspective of the Government of Spain, he was removed from office by Prime Minister Mariano Rajoy on 28 October 2017. Puigdemont did not recognize his removal from office, stating that he will \"work to build a free country\".\n",
            "[0.146]\tAfter committal for trial, the preliminary inquiry judge set a tentative trial for September 8, 2014 on April 29, 2013. On 29 September 2014 in court in Quebec, Magnotta admitted killing Jun Lin. He pleaded not guilty to murder due to his schizophrenia. He has been diagnosed with borderline personality disorder and histrionic personality disorder.\n",
            "\n",
            "\n",
            "\n",
            "[0.279]\tLogic gates are digital components. They normally work at only two levels of voltage, a positive level and zero level. Commonly they work based on two states: \"On\" and \"Off\". In the On state, voltage is positive. In the Off state, the voltage is at zero. The On state usually uses a voltage in the range of 3.5 to 5 volts. This range can be lower for some uses.\n",
            "[0.242]\tLogic gates compare the state at their inputs to decide what the state at their output should be. A logic gate is \"on\" or active when its rules are correctly met. At this time, electricity is flowing through the gate and the voltage at its output is at the level of its On state.\n",
            "[0.240]\tUsing the image at the right, if \"A\" and \"B\" are both in an On state, the output (out) will be an On state. If either \"A\" or \"B\" is in an Off state, the output will also be in an Off state. \"A\" and \"B\" must be On for the output to be On.\n",
            "[0.218]\tUsing the image at the right, if either \"A\" or \"B\" is On, the output (\"out\") will also be On. If both \"A\" and \"B\" are Off, the output will be Off.\n",
            "[0.181]\tOR gates have two inputs. The output of an OR gate will be on if at least one of the inputs are on. If both inputs are off, the output will be off.\n",
            "\n",
            "\n",
            "\n",
            "[0.268]\tHere is a list of the provinces and territories, and their standard abbreviations, with their capitals (the cities where their governments are based) and largest cities. Canada's national capital, where the federal government meets, is Ottawa.\n",
            "[0.199]\tThe head of government is the Prime Minister. The current prime minister is Justin Trudeau, who replaced Stephen Harper in October 2015. Each province and territory has a premier to lead its government. The day-to-day operations of the government are run by the cabinet. The cabinet is usually formed from the largest party in Parliament.\n",
            "[0.193]\tThe different levels of government in Canada are based on the principles of a federation: the governments of each province and territory share power with the federal government. The territories' governments have a more limited set of powers than the federal government.\n",
            "[0.165]\tCanada is a country and sovereign state in the north of North America. It is made up of thirteen administrative divisions: ten provinces and three territories.\n",
            "[0.160]\tCanada has a government called a constitutional monarchy. It has a monarch (meaning a king or queen is the head of that country), and is a democracy (meaning the people of that country rule it). The head of state is King Charles III, who is officially the King of Canada. He appoints a Governor General to represent him in the country, however, the choice of Governor General is made by the prime minister.\n",
            "\n",
            "\n",
            "\n",
            "[0.239]\tThe question now is: at the end of the hour, is the cat alive or dead? Schrödinger says that according to the Copenhagen Interpretation, as long as the door is closed, the cat is dead and alive. There is no way to know until the door is opened. But by opening the door, the person is interfering with the experiment. The person and the experiment have to be described with reference to each other.\n",
            "[0.196]\tThe Copenhagen interpretation is used to explain what is happening to the smallest part of an atom (a sub atomic particle) without looking at it (observing it or measuring it). Mathematics are used to show how likely something is to happen to the particle. A particle could be described as being 50% likely to be in one place at one time, or 50% likely to be in one place at another time. This could also be expressed as a chart (or wave form). This is very convenient when making quantum physics calculations.\n",
            "[0.161]\tHowever the only way to be 100% sure of where a particle is, is to observe it. Up until the point that you observe it, the Copenhagen Interpretation says that the particle is there and is not there. It is only when you observe the particle that you know if it's there or not there.\n",
            "[0.157]\tIn simple terms, Schrödinger stated that if you place a cat and something that could kill the cat (a radioactive atom) in a box and sealed it, you would not know if the cat was dead or alive until you opened the box, so that until the box was opened, the cat was (in a sense) \"both\" \"dead and alive\". This is used to represent how scientific theory works. No one knows if any scientific theory is right or wrong until said theory can be tested and proved.\n",
            "[0.150]\t\"If the material breaks down, it will release an atomic particle, which will hit the geiger counter, which will release poison gas, which will kill the cat.\"\n",
            "\n",
            "\n",
            "\n",
            "[0.210]\tThe present global warming is mostly because of people burning things, like gasoline for cars and natural gas to keep houses warm. But the heat from the burning itself only makes the world a tiny bit warmer: \"it is the carbon dioxide from the burning which is the biggest part of the problem\". Among greenhouse gases, the increase of carbon dioxide in the atmosphere is the main cause of global warming. Svante Arrhenius predicted this more than a hundred years ago. Arrhenius confirmed the work of Joseph Fourier 200 years ago.\n",
            "[0.209]\tThere are several greenhouse gases that cause the Earth to warm. The most important one is carbon dioxide (CO). CO comes from power plants which burn coal and natural gas to make electricity. Cars also emit CO when they burn petrol. About 35 billion tons of carbon dioxide are released into the Earth's atmosphere each year. The amount of CO in the air is about 50% more than it was around 1750. About three-quarters of the CO that people have put in the air during the past 20 years are due to burning fossil fuel like coal or oil. The rest mostly comes from changes in how land is used, like cutting down trees.\n",
            "[0.191]\tWhen people burn fossil fuels like coal, oil and natural gas this adds carbon dioxide into the air. This is because fossil fuels contain lots of carbon and burning means joining most of the atoms in the fuel with oxygen. When people cut down many trees (deforestation), this means less carbon dioxide is taken out of the atmosphere by those plants. Animals which have four places in their stomachs, like cows and sheep, also cause global warming, because their burps contain a greenhouse gas called methane.\n",
            "[0.181]\tEnergy conservation is used to burn less fossil fuel. People can also use energy sources that don't burn fossil fuel, like solar panels or electricity from nuclear power or wind power. Or they can prevent the carbon dioxide from getting out into the atmosphere, which is called carbon capture and storage (CCS).\n",
            "[0.172]\tThe second most important greenhouse gas is methane. A tonne of methane is much more warming than a tonne of CO but methane stays in the atmosphere for only about ten years. About 40% comes from nature, like wetlands; and the rest is because of humans, like cows, landfill and leaks when oil and gas are produced.\n",
            "\n",
            "\n",
            "\n",
            "[0.203]\tIn the early 1900s, millions of people peacefully started to protest against British control. One of the people who led the freedom movement was Mahatma Gandhi, who only used peaceful tactics, including a way called \"ahimsa\", which means \"non-violence\". On 15 August 1947, India peacefully became free and independent from the British Empire. India's constitution was founded on 26 January 1950. Every year, on this day, Indians celebrate Republic Day. The first official leader (Prime Minister) of India was Jawaharlal Nehru.\n",
            "[0.119]\tHe also had a dream for the future India. He wanted India's freedom from the British rule. He dreamt of an India \"where the mind is without fear it is \".\n",
            "[0.101]\tHe wanted to free South Africa without violence, but the government started killing and hurting protesters. He then started Umkhonto we Sizwe with Walter Sisulu and other people in the African National Congress that he admired, such as Mahatma Gandhi.\n",
            "[0.088]\tThe British Crown gave Tagore a knighthood in 1915. However, he gave back the title in 1919 to protest the Jallianwala Bagh Massacre in Amritsar. During this massacre, troops of the British Raj killed people who had no weapons.\n",
            "[0.085]\t\"We stand here today as nothing more than a representative of the millions of our people who dared to rise up against a social operation whose very essence is war, violence, racism, oppression, repression and the impoverishment of an entire people.\"\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LN67-A-H1jt1"
      },
      "source": [
        "# 04. Context Retreival from Original Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "def get_cosine_context(query_embeddings: np.ndarray, chunks, top_k: int = 5):\n",
        "    vectors = np.array([chunk['emb'] for chunk in chunks])\n",
        "    texts = [chunk['text'] for chunk in chunks]\n",
        "\n",
        "    cosine_contexts_scores = []\n",
        "    similarities = cosine_similarity(query_embeddings, vectors)  # shape: (n_queries, n_chunks)\n",
        "\n",
        "    for query_sim in similarities:  # shape: (n_chunks,)\n",
        "        # Get top_k efficiently\n",
        "        top_k_indices = np.argpartition(-query_sim, top_k)[:top_k]\n",
        "        top_k_indices = top_k_indices[np.argsort(-query_sim[top_k_indices])]\n",
        "\n",
        "        context = [texts[i] for i in top_k_indices]\n",
        "        context_score = [query_sim[i] for i in top_k_indices]\n",
        "        cosine_contexts_scores.append((context, context_score))\n",
        "\n",
        "    return cosine_contexts_scores"
      ],
      "metadata": {
        "id": "G-FF2BGya39i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_contexts_scores = get_cosine_context(original_query_embeddings, docs)"
      ],
      "metadata": {
        "id": "IjnEuetzRnoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for r in cosine_contexts_scores:\n",
        "  # print(f\"[{r[1]:.3f}]\\t{r[0]}\")\n",
        "  for txt, score in zip(r[0],r[1]):\n",
        "    print(f\"[{score:.3f}]\\t{txt}\")\n",
        "  print('\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIMxAPHdy2sk",
        "outputId": "77678326-b212-427b-876c-cceded1fdeb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.911]\t24-hour clock time is used in computers, military, public safety, and transport. In many Asian, European and Latin American countries people use it to write the time. Many European people use it in speaking.\n",
            "[0.898]\tThe 24-hour clock is a way of telling the time in which the day runs from midnight to midnight and is divided into 24 hours, numbered from 0 to 23. It does not use a.m. or p.m. This system is also referred to (only in the US and the English speaking parts of Canada) as military time or (only in the United Kingdom and now very rarely) as continental time. In some parts of the world, it is called railway time. Also, the international standard notation of time (ISO 8601) is based on this format.\n",
            "[0.894]\tHowever, the US military prefers not to say 24:00 - they do not like to have two names for the same thing, so they always say \"23:59\", which is one minute before midnight.\n",
            "[0.879]\tA time in the 24-hour clock is written in the form hours:minutes (for example, 01:23), or hours:minutes:seconds (01:23:45). Numbers under 10 have a zero in front (called a leading zero); e.g. 09:07. Under the 24-hour clock system, the day begins at midnight, 00:00, and the last minute of the day begins at 23:59 and ends at 24:00, which is identical to 00:00 of the following day. 12:00 can only be mid-day. Midnight is called 24:00 and is used to mean the end of the day and 00:00 is used to mean the beginning of the day. For example, you would say \"Tuesday at 24:00\" and \"Wednesday at 00:00\" to mean exactly the same time.\n",
            "[0.875]\tIn railway timetables 24:00 means the \"end\" of the day. For example, a train due to arrive at a station during the last minute of a day arrives at 24:00; but trains which depart during the first minute of the day go at 00:00.\n",
            "\n",
            "\n",
            "\n",
            "[0.888]\tThe collection contains different texts, called \"books\", about God, and the people of Israel. It can be divided into several sections: the Torah, the History of Israel, the Prophets and Wisdom books. In Judaism, this collection of books is known as Tanakh because it is divided into three parts (Torah, Nevi'im and Ketuvim). Most Jews and many Christians believe these texts to be holy. According to them, God inspired people to write them.\n",
            "[0.861]\tSpecific articles are included in the Catechism of the Catholic Church relating to the education of children.\n",
            "[0.860]\tIn Christianity, the Old Testament is the name of the first part of the Bible which was completed before Jesus Christ was born. Scholars prefer the term Hebrew Bible.\n",
            "[0.858]\tOther themes in the Old Testament include salvation, redemption, divine judgment, obedience and disobedience, faith and faithfulness. Throughout there is a strong emphasis on ethics and ritual purity. God demands both.\n",
            "[0.855]\tIndia's government is divided into three parts: the Legislative (the one that makes the laws, the Parliament), the Executive (the government), and the Judiciary (the one that makes sure that the laws are obeyed, the supreme court).\n",
            "\n",
            "\n",
            "\n",
            "[0.930]\tIn both \"Batman Begins\" and in \"The Dark Knight\", Gotham City was shot in Chicago, Illinois. In \"The Dark Knight Rises,\" Gotham City was shot in Pittsburgh, Pennsylvania, New York City, New York, and Los Angeles, California.\n",
            "[0.850]\tThese and the other cities have either started trying to deal with rising sea level and related storm surge, or are discussing this, according to .\n",
            "[0.822]\tUnited States, British Empire, France, Soviet Union, Australia, Belgium, Brazil, Canada, China, Denmark, Greece, Netherlands, New Zealand, Norway, Poland, South Africa, Yugoslavia\n",
            "[0.818]\tMost authorities now agree that of the 30 million Soviets who bore arms, there were 13.6 million military deaths.\n",
            "[0.817]\tThe \"Dark Knight\" Series is a set of three Christopher Nolan Batman movies. It includes \"Batman Begins\" (2005), \"The Dark Knight\" (2008), and \"The Dark Knight Rises\" (2012). Christian Bale, Michael Caine, Gary Oldman, Morgan Freeman, and Cillian Murphy appeared in all three movies.\n",
            "\n",
            "\n",
            "\n",
            "[0.878]\tIn June 2019, Ronaldo won the UEFA Nations League with Portugal to give him his second international title. In the final, Portugal beat The Netherlands 1-0.\n",
            "[0.868]\tOn 2 November 2011, Ronaldo scored both goals in a 2-0 Champions League group stage win against Olympique Lyon. The second goal was his 100th goal for Real Madrid. He achieved this in just 105 matches. He scored his 100th La Liga goal for his club in just 92 appearances in a 5-1 win against Real Sociedad on 24 March 2012.\n",
            "[0.864]\tOn 18 April 2017, he became the first player to reach 100 goals in the UEFA Champions League, after he scored a hat-trick in a 4-2 extra-time win against Bayern Munich. On 18 March 2018, Ronaldo reached his 50th career hat-trick in a 6-3 win against Girona. Ronaldo scored an amazing bicycle-kick in a UEFA Champions League match against Juventus on 3 April 2018. He got a standing ovation, or round of applause, from the Juventus fans after scoring that goal. Real Madrid went on to play the final against Liverpool F.C.. Real Madrid became champions, so that was Ronaldo's 5th Champions League.\n",
            "[0.864]\tIn June 2018, Ronaldo was given a suspended jail sentence of 2 years and a fine of €18.8 million for tax evasion.\n",
            "[0.849]\tHe kept progressing through the youth national teams until he played his first senior game for Portugal when he was 18 on 20 August 2003 against Kazakhstan. He scored his first goal for Portugal in a game against Greece at the UEFA Euro 2004.\n",
            "\n",
            "\n",
            "\n",
            "[0.916]\tOn 25 March 2018, while returning to Brussels from a trip to Finland, Puigdemont was stopped near the Danish border with Germany and arrested pursuant to the European warrant that had been reissued against him two days previously. On 5 April 2018, the Oberlandesgericht in the German state of Schleswig-Holstein ruled that Puigdemont would not be extradited on the charges of rebellion, and released him on bail.\n",
            "[0.910]\tOn 30 October 2017, Puigdemont fled to Belgium in a move to avoid action from the Spanish judiciary. A month later, he was re-elected to the Parliament.\n",
            "[0.910]\tOn 2 November, Spanish courts issued an European Arrest Warrant against Puigdemont and four other cabinet members to Belgian authorities. Two days later, they turned themselves in to the Belgian police. Hours later, he was released.\n",
            "[0.868]\tThe government can also control people and what happens in a country in other ways besides making laws.\n",
            "[0.862]\tAlthough many Axis war crimes were brought to the first international court, no Allied war crimes were.\n",
            "\n",
            "\n",
            "\n",
            "[0.920]\tLogic gates compare the state at their inputs to decide what the state at their output should be. A logic gate is \"on\" or active when its rules are correctly met. At this time, electricity is flowing through the gate and the voltage at its output is at the level of its On state.\n",
            "[0.914]\tLogic gates are digital components. They normally work at only two levels of voltage, a positive level and zero level. Commonly they work based on two states: \"On\" and \"Off\". In the On state, voltage is positive. In the Off state, the voltage is at zero. The On state usually uses a voltage in the range of 3.5 to 5 volts. This range can be lower for some uses.\n",
            "[0.888]\tUsing the image at the right, if \"A\" and \"B\" are both in an On state, the output (out) will be an On state. If either \"A\" or \"B\" is in an Off state, the output will also be in an Off state. \"A\" and \"B\" must be On for the output to be On.\n",
            "[0.882]\tUsing the image at the right, if either \"A\" or \"B\" is On, the output (\"out\") will also be On. If both \"A\" and \"B\" are Off, the output will be Off.\n",
            "[0.879]\tLogic gates are electronic versions of Boolean logic. Truth tables will tell you what the output will be, depending on the inputs.\n",
            "\n",
            "\n",
            "\n",
            "[0.904]\tHere is a list of the provinces and territories, and their standard abbreviations, with their capitals (the cities where their governments are based) and largest cities. Canada's national capital, where the federal government meets, is Ottawa.\n",
            "[0.884]\tThe different levels of government in Canada are based on the principles of a federation: the governments of each province and territory share power with the federal government. The territories' governments have a more limited set of powers than the federal government.\n",
            "[0.868]\tThe head of government is the Prime Minister. The current prime minister is Justin Trudeau, who replaced Stephen Harper in October 2015. Each province and territory has a premier to lead its government. The day-to-day operations of the government are run by the cabinet. The cabinet is usually formed from the largest party in Parliament.\n",
            "[0.863]\tThe government can also control people and what happens in a country in other ways besides making laws.\n",
            "[0.863]\tCanada is a country and sovereign state in the north of North America. It is made up of thirteen administrative divisions: ten provinces and three territories.\n",
            "\n",
            "\n",
            "\n",
            "[0.885]\tThe question now is: at the end of the hour, is the cat alive or dead? Schrödinger says that according to the Copenhagen Interpretation, as long as the door is closed, the cat is dead and alive. There is no way to know until the door is opened. But by opening the door, the person is interfering with the experiment. The person and the experiment have to be described with reference to each other.\n",
            "[0.857]\tHowever the only way to be 100% sure of where a particle is, is to observe it. Up until the point that you observe it, the Copenhagen Interpretation says that the particle is there and is not there. It is only when you observe the particle that you know if it's there or not there.\n",
            "[0.851]\tIn simple terms, Schrödinger stated that if you place a cat and something that could kill the cat (a radioactive atom) in a box and sealed it, you would not know if the cat was dead or alive until you opened the box, so that until the box was opened, the cat was (in a sense) \"both\" \"dead and alive\". This is used to represent how scientific theory works. No one knows if any scientific theory is right or wrong until said theory can be tested and proved.\n",
            "[0.851]\tSchrödinger's cat is a thought experiment about quantum physics. Erwin Schrödinger suggested it in 1935, in reaction to the Copenhagen interpretation of quantum physics.\n",
            "[0.850]\t\"If the material breaks down, it will release an atomic particle, which will hit the geiger counter, which will release poison gas, which will kill the cat.\"\n",
            "\n",
            "\n",
            "\n",
            "[0.906]\tThe present global warming is mostly because of people burning things, like gasoline for cars and natural gas to keep houses warm. But the heat from the burning itself only makes the world a tiny bit warmer: \"it is the carbon dioxide from the burning which is the biggest part of the problem\". Among greenhouse gases, the increase of carbon dioxide in the atmosphere is the main cause of global warming. Svante Arrhenius predicted this more than a hundred years ago. Arrhenius confirmed the work of Joseph Fourier 200 years ago.\n",
            "[0.896]\tClimate change has happened constantly over the history of the Earth, including the coming and going of ice ages. But modern climate change is different because people are putting carbon dioxide into the atmosphere more quickly than before.\n",
            "[0.893]\tIn the mid 20th century, scientists worked out that there was a 10% increase in carbon dioxide in the atmosphere over the 19th century, which made it a bit warmer. It was at this time that people believed the emissions of CO would increase exponentially in the future and the oceans would absorb any surplus of greenhouse gases. In 1956, Gilbert N. Plass decided that greenhouse gas emissions would have an effect on the Earth’s temperature. He argued that not thinking about GHG emissions would be a mistake. Soon after, scientists studying all different kinds of science began to work together to figure out the mystery of GHG emissions and their effects. As technology advanced, it was in the 1980s that there was proof of a rise in CO levels. An ice core, captured through drilling, provided clear evidence that carbon dioxide levels have risen.\n",
            "[0.880]\tIn the Paris Agreement almost all governments agreed to keep temperature rise below , but current plans are not enough to limit global warming that much. People in government and the Intergovernmental Panel on Climate Change (IPCC) are talking about global warming. But governments, companies, and other people do not agree on what to do about it. Some things that could reduce warming are to burn less fossil fuels, grow more trees, eat less meat, and put some carbon dioxide back in the ground. People could adapt to some temperature change. A few people think nothing should change.\n",
            "[0.878]\tSome people burn less fossil fuel. Countries try to emit less greenhouse gases. The Kyoto Protocol was signed in 1997. It was meant to reduce the amount of greenhouse gases in the atmosphere to below their levels in 1990. However, carbon dioxide levels have continued to rise.\n",
            "\n",
            "\n",
            "\n",
            "[0.865]\tHe also had a dream for the future India. He wanted India's freedom from the British rule. He dreamt of an India \"where the mind is without fear it is \".\n",
            "[0.861]\t\"We stand here today as nothing more than a representative of the millions of our people who dared to rise up against a social operation whose very essence is war, violence, racism, oppression, repression and the impoverishment of an entire people.\"\n",
            "[0.860]\tThe government can also control people and what happens in a country in other ways besides making laws.\n",
            "[0.856]\tHe won the Nobel Peace Prize for his leadership for his anti-apartheid activism in 1993. After receiving the prize he said:\n",
            "[0.855]\tIn the early 1900s, millions of people peacefully started to protest against British control. One of the people who led the freedom movement was Mahatma Gandhi, who only used peaceful tactics, including a way called \"ahimsa\", which means \"non-violence\". On 15 August 1947, India peacefully became free and independent from the British Empire. India's constitution was founded on 26 January 1950. Every year, on this day, Indians celebrate Republic Day. The first official leader (Prime Minister) of India was Jawaharlal Nehru.\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import tracemalloc\n",
        "import logging\n",
        "\n",
        "# Enable logging if desired\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def benchmark_function(func, *args, **kwargs):\n",
        "    logger.info(f\"Running {func.__name__}...\")\n",
        "\n",
        "    # Start memory tracking\n",
        "    tracemalloc.start()\n",
        "\n",
        "    # Start timing\n",
        "    start_time = time.perf_counter()\n",
        "    result = func(*args, **kwargs)\n",
        "    end_time = time.perf_counter()\n",
        "\n",
        "    # Measure memory usage\n",
        "    current, peak = tracemalloc.get_traced_memory()\n",
        "    tracemalloc.stop()\n",
        "\n",
        "    logger.info(f\"{func.__name__} completed.\")\n",
        "    logger.info(f\"Time taken: {end_time - start_time:.4f} seconds\")\n",
        "    logger.info(f\"Peak memory usage: {peak / 1024:.2f} KB\")\n",
        "\n",
        "    return result, end_time - start_time, peak"
      ],
      "metadata": {
        "id": "PWQvUHqB8ZME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run and benchmark reduced_dim_retreival\n",
        "som_contexts_scores, time1, mem1 = benchmark_function(\n",
        "    reduced_dim_retreival, np_embeddings, original_query_embeddings, test_case, sm\n",
        ")\n",
        "\n",
        "# Run and benchmark get_cosine_context\n",
        "cosine_contexts_scores, time2, mem2 = benchmark_function(\n",
        "    get_cosine_context, original_query_embeddings, docs\n",
        ")\n",
        "\n",
        "# Print final comparison\n",
        "print(\"\\n🔍 Performance Comparison:\")\n",
        "print(f\"reduced_dim_retreival: {time1:.4f} sec, {mem1 / 1024:.2f} KB peak memory\")\n",
        "print(f\"get_cosine_context:     {time2:.4f} sec, {mem2 / 1024:.2f} KB peak memory\")"
      ],
      "metadata": {
        "id": "8nbLFwhJy2v3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52bd5789-60cd-429d-9c12-ee3d76950418"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Performance Comparison:\n",
            "reduced_dim_retreival: 0.1329 sec, 3069.48 KB peak memory\n",
            "get_cosine_context:     0.0694 sec, 12150.05 KB peak memory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Benchmark SOM training\n",
        "sm, train_time, train_mem = benchmark_function(\n",
        "    train_som_model,\n",
        "    np_embeddings,\n",
        "    test_case['mapsize'],\n",
        "    test_case['normalization'],\n",
        "    test_case['initialization'],\n",
        "    test_case['lattice'],\n",
        "    test_case['neighborhood'],\n",
        "    test_case['training'],\n",
        "    test_case['name'],\n",
        "    test_case['rough_len'],\n",
        "    test_case['finetune_len']\n",
        ")\n",
        "\n",
        "print(\"\\n🧠 SOM Training Benchmark:\")\n",
        "print(f\"train_som_model: {train_time:.4f} sec, {train_mem / 1024:.2f} KB peak memory\")"
      ],
      "metadata": {
        "id": "1ZI6cBHLy20S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "848ec643-f28b-492a-ef07-6988b49ee652"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🧠 SOM Training Benchmark:\n",
            "train_som_model: 179.4612 sec, 30930.50 KB peak memory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "00A5SUMOy25X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dQXenw3CVV8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OUjU9u0NVWAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "49uBWJhlVWD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WLjecNHYVWHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BKepSgo9VWJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions_file='Wikipedia_Questions2.txt'"
      ],
      "metadata": {
        "id": "njwytGa64Cjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_C1z84S9eGa"
      },
      "outputs": [],
      "source": [
        "def get_questions_from_file(questions_file):\n",
        "  \"\"\"\n",
        "  Reads a file and extracts lines that start with a digit as questions.\n",
        "\n",
        "  Args:\n",
        "    questions_file: The path to the file containing the questions.\n",
        "\n",
        "  Returns:\n",
        "    A list of strings, where each string is a question.\n",
        "  \"\"\"\n",
        "  questions = []\n",
        "\n",
        "  try:\n",
        "    with open(questions_file, \"r\", encoding=\"utf-8\") as file:\n",
        "      for line in file:\n",
        "        stripped = line.strip()\n",
        "        if stripped and stripped[0].isdigit():\n",
        "          questions.append(stripped)\n",
        "  except FileNotFoundError:\n",
        "    print(f\"Error: The file '{questions_file}' was not found.\")\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred while reading the file: {e}\")\n",
        "\n",
        "  return questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knEYUPjRFEpF",
        "outputId": "86ec4ebc-1358-4dc6-841c-d3ad058bfa9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. What is the international standard that uses the 24-hour clock format?\n",
            "2. Which three parts make up the Tanakh in Judaism?\n",
            "3. In which three cities was Gotham City filmed for The Dark Knight Rises?\n",
            "4. Against which team did Ronaldo score his famous bicycle-kick goal in the 2018 UEFA Champions League?\n",
            "5. Which German state’s court ruled on 5 April 2018 that Puigdemont would not be extradited on charges of rebellion?\n",
            "6. What is the voltage range typically used to represent the On state in a logic gate?\n",
            "7. Where is Canada's national capital, where the federal government meets?\n",
            "8. According to the Copenhagen Interpretation, what state is the cat in before the box is opened?\n",
            "9. What gas is identified as the main cause of global warming due to burning fossil fuels?\n",
            "10. Which Indian leader used peaceful tactics including \"ahimsa\" to lead the freedom movement against British rule?\n"
          ]
        }
      ],
      "source": [
        "questions = get_questions_from_file(questions_file)[:10]\n",
        "\n",
        "for q in questions:\n",
        "    print(q)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "questions = ['1. What is the international standard that uses the 24-hour clock format?',\n",
        " '2. Which three parts make up the Tanakh in Judaism?',\n",
        " '3. In which three cities was Gotham City filmed for The Dark Knight Rises?',\n",
        " '4. Against which team did Ronaldo score his famous bicycle-kick goal in the 2018 UEFA Champions League?',\n",
        " '5. Which German state’s court ruled on 5 April 2018 that Puigdemont would not be extradited on charges of rebellion?',\n",
        " '6. What is the voltage range typically used to represent the On state in a logic gate?',\n",
        " \"7. Where is Canada's national capital, where the federal government meets?\",\n",
        " '8. According to the Copenhagen Interpretation, what state is the cat in before the box is opened?',\n",
        " '9. What gas is identified as the main cause of global warming due to burning fossil fuels?',\n",
        " '10. Which Indian leader used peaceful tactics including \"ahimsa\" to lead the freedom movement against British rule?']"
      ],
      "metadata": {
        "id": "MyJ-5sCxftKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-y2RNRND0ay"
      },
      "source": [
        "### 7.2 Get context for each question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bBw1qQZs-Os"
      },
      "outputs": [],
      "source": [
        "def embed_all_questions(questions: list[str],\n",
        "                 model: str = 'multilingual-22-12',\n",
        "                 input_type: str = 'search_query',\n",
        "                 output_dimenion: int = wik_embeddings.shape[1]) -> np.ndarray:\n",
        "  query_embeddings = []\n",
        "  for q in questions:\n",
        "    query_embedding = embed_prompt(q)\n",
        "    query_embeddings.append(query_embedding)\n",
        "  return query_embeddings\n",
        "\n",
        "# Function to retrieve SOM context\n",
        "def get_som_all(questions, query_embeddings):\n",
        "  all_som_context = []\n",
        "  for q,q_emb in zip(questions,query_embeddings):\n",
        "      context,score = get_som_context(q_emb, sm, valid_bmu_hit_vectors_with_indices, docs)\n",
        "      all_som_context.append(context)\n",
        "  return all_som_context\n",
        "\n",
        "# Function to retrieve cosine similarity context\n",
        "def get_cosine_all(questions, query_embeddings):\n",
        "  all_cosine_context = []\n",
        "  for q, q_emb in zip(questions,query_embeddings):\n",
        "      context,score = get_cosine_context(q_emb, docs)\n",
        "      all_cosine_context.append(context)\n",
        "  return all_cosine_context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZXPo7U8s-Sh",
        "outputId": "79fb7198-363c-40ca-f59a-fd29c94e0278",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new shape :  (1, 768)\n",
            "q_vec shape :  (1, 768)\n",
            "vectors shape : (84, 768)\n",
            "indices shape : (84,)\n",
            "normed_query_embedding shape : (1, 768)\n",
            "similarities shape : (1, 84)\n",
            "max_similarity_idx : 10\n",
            "selected_bmu_index : 11\n",
            "Found 1 candidates\n",
            "vectors shape : (1, 768)\n",
            "indices shape : (1,)\n",
            "normed_query_embedding shape : (1, 768)\n",
            "similarities shape : (1, 1)\n",
            "scores length:  1\n",
            "sorted_indices_desc length:  1\n",
            "[0]\n",
            "top_k_chunk_indices :  [936]\n",
            "new shape :  (1, 768)\n",
            "q_vec shape :  (1, 768)\n",
            "vectors shape : (84, 768)\n",
            "indices shape : (84,)\n",
            "normed_query_embedding shape : (1, 768)\n",
            "similarities shape : (1, 84)\n",
            "max_similarity_idx : 46\n",
            "selected_bmu_index : 55\n",
            "Found 9 candidates\n",
            "vectors shape : (9, 768)\n",
            "indices shape : (9,)\n",
            "normed_query_embedding shape : (1, 768)\n",
            "similarities shape : (1, 9)\n",
            "scores length:  9\n",
            "sorted_indices_desc length:  9\n",
            "[2 0 3 6 1 4 5 8 7]\n",
            "top_k_chunk_indices :  [7, 5, 8, 11, 6]\n",
            "new shape :  (1, 768)\n",
            "q_vec shape :  (1, 768)\n",
            "vectors shape : (84, 768)\n",
            "indices shape : (84,)\n",
            "normed_query_embedding shape : (1, 768)\n",
            "similarities shape : (1, 84)\n",
            "max_similarity_idx : 52\n",
            "selected_bmu_index : 62\n",
            "Found 1 candidates\n",
            "vectors shape : (1, 768)\n",
            "indices shape : (1,)\n",
            "normed_query_embedding shape : (1, 768)\n",
            "similarities shape : (1, 1)\n",
            "scores length:  1\n",
            "sorted_indices_desc length:  1\n",
            "[0]\n",
            "top_k_chunk_indices :  [501]\n",
            "new shape :  (1, 768)\n",
            "q_vec shape :  (1, 768)\n",
            "vectors shape : (84, 768)\n",
            "indices shape : (84,)\n",
            "normed_query_embedding shape : (1, 768)\n",
            "similarities shape : (1, 84)\n",
            "max_similarity_idx : 69\n",
            "selected_bmu_index : 80\n",
            "Found 8 candidates\n",
            "vectors shape : (8, 768)\n",
            "indices shape : (8,)\n",
            "normed_query_embedding shape : (1, 768)\n",
            "similarities shape : (1, 8)\n",
            "scores length:  8\n",
            "sorted_indices_desc length:  8\n",
            "[6 1 0 4 7 2 3 5]\n",
            "top_k_chunk_indices :  [59, 41, 28, 57, 60]\n",
            "new shape :  (1, 768)\n",
            "q_vec shape :  (1, 768)\n",
            "vectors shape : (84, 768)\n",
            "indices shape : (84,)\n",
            "normed_query_embedding shape : (1, 768)\n",
            "similarities shape : (1, 84)\n",
            "max_similarity_idx : 59\n",
            "selected_bmu_index : 70\n",
            "Found 6 candidates\n",
            "vectors shape : (6, 768)\n",
            "indices shape : (6,)\n",
            "normed_query_embedding shape : (1, 768)\n",
            "similarities shape : (1, 6)\n",
            "scores length:  6\n",
            "sorted_indices_desc length:  6\n",
            "[4 3 2 1 0 5]\n",
            "top_k_chunk_indices :  [65, 64, 63, 62, 61]\n",
            "new shape :  (1, 768)\n",
            "q_vec shape :  (1, 768)\n",
            "vectors shape : (84, 768)\n",
            "indices shape : (84,)\n",
            "normed_query_embedding shape : (1, 768)\n",
            "similarities shape : (1, 84)\n",
            "max_similarity_idx : 9\n",
            "selected_bmu_index : 10\n",
            "Found 12 candidates\n",
            "vectors shape : (12, 768)\n",
            "indices shape : (12,)\n",
            "normed_query_embedding shape : (1, 768)\n",
            "similarities shape : (1, 12)\n",
            "scores length:  12\n",
            "sorted_indices_desc length:  12\n",
            "[ 0  1  4  6  5  7  3  9  2  8 10 11]\n",
            "top_k_chunk_indices :  [67, 68, 71, 73, 72]\n",
            "new shape :  (1, 768)\n",
            "q_vec shape :  (1, 768)\n",
            "vectors shape : (84, 768)\n",
            "indices shape : (84,)\n",
            "normed_query_embedding shape : (1, 768)\n",
            "similarities shape : (1, 84)\n",
            "max_similarity_idx : 8\n",
            "selected_bmu_index : 9\n",
            "Found 40 candidates\n",
            "vectors shape : (40, 768)\n",
            "indices shape : (40,)\n",
            "normed_query_embedding shape : (1, 768)\n",
            "similarities shape : (1, 40)\n",
            "scores length:  40\n",
            "sorted_indices_desc length:  40\n",
            "[ 3  1 31  2 39  0 23 29 12 10 30  6 14  9 36 19 37 32 38 28 15 35 21 25\n",
            " 13 26 34 24 11 33 16  7 27 18 22  4 17  8 20  5]\n",
            "top_k_chunk_indices :  [85, 83, 900, 84, 908]\n",
            "new shape :  (1, 768)\n",
            "q_vec shape :  (1, 768)\n",
            "vectors shape : (84, 768)\n",
            "indices shape : (84,)\n",
            "normed_query_embedding shape : (1, 768)\n",
            "similarities shape : (1, 84)\n",
            "max_similarity_idx : 45\n",
            "selected_bmu_index : 53\n",
            "Found 17 candidates\n",
            "vectors shape : (17, 768)\n",
            "indices shape : (17,)\n",
            "normed_query_embedding shape : (1, 768)\n",
            "similarities shape : (1, 17)\n",
            "scores length:  17\n",
            "sorted_indices_desc length:  17\n",
            "[ 8  2  3  1  7  6  0  4  9  5 10 12 14 13 16 15 11]\n",
            "top_k_chunk_indices :  [104, 98, 99, 96, 103]\n",
            "new shape :  (1, 768)\n",
            "q_vec shape :  (1, 768)\n",
            "vectors shape : (84, 768)\n",
            "indices shape : (84,)\n",
            "normed_query_embedding shape : (1, 768)\n",
            "similarities shape : (1, 84)\n",
            "max_similarity_idx : 14\n",
            "selected_bmu_index : 16\n",
            "Found 23 candidates\n",
            "vectors shape : (23, 768)\n",
            "indices shape : (23,)\n",
            "normed_query_embedding shape : (1, 768)\n",
            "similarities shape : (1, 23)\n",
            "scores length:  23\n",
            "sorted_indices_desc length:  23\n",
            "[ 1  9  2 14 10 19 18  0 13 11  5  4 17 12 21 20 16  6 15  3 22  8  7]\n",
            "top_k_chunk_indices :  [108, 116, 109, 121, 117]\n",
            "new shape :  (1, 768)\n",
            "q_vec shape :  (1, 768)\n",
            "vectors shape : (84, 768)\n",
            "indices shape : (84,)\n",
            "normed_query_embedding shape : (1, 768)\n",
            "similarities shape : (1, 84)\n",
            "max_similarity_idx : 71\n",
            "selected_bmu_index : 83\n",
            "Found 1 candidates\n",
            "vectors shape : (1, 768)\n",
            "indices shape : (1,)\n",
            "normed_query_embedding shape : (1, 768)\n",
            "similarities shape : (1, 1)\n",
            "scores length:  1\n",
            "sorted_indices_desc length:  1\n",
            "[0]\n",
            "top_k_chunk_indices :  [713]\n",
            "som_context[0] length : 294\n",
            "new shape :  (1, 768)\n",
            "q_vec shape :  (1, 768)\n",
            "Found 1000 candidates\n",
            "vectors shape : (1000, 768)\n",
            "indices shape : (1000,)\n",
            "normed_query_embedding shape : (1, 768)\n",
            "similarities shape : (1, 1000)\n",
            "scores length:  1000\n",
            "sorted_indices_desc length:  1000\n",
            "new shape :  (1, 768)\n",
            "q_vec shape :  (1, 768)\n",
            "Found 1000 candidates\n",
            "vectors shape : (1000, 768)\n",
            "indices shape : (1000,)\n",
            "normed_query_embedding shape : (1, 768)\n",
            "similarities shape : (1, 1000)\n",
            "scores length:  1000\n",
            "sorted_indices_desc length:  1000\n",
            "new shape :  (1, 768)\n",
            "q_vec shape :  (1, 768)\n",
            "Found 1000 candidates\n",
            "vectors shape : (1000, 768)\n",
            "indices shape : (1000,)\n",
            "normed_query_embedding shape : (1, 768)\n",
            "similarities shape : (1, 1000)\n",
            "scores length:  1000\n",
            "sorted_indices_desc length:  1000\n",
            "new shape :  (1, 768)\n",
            "q_vec shape :  (1, 768)\n",
            "Found 1000 candidates\n",
            "vectors shape : (1000, 768)\n",
            "indices shape : (1000,)\n",
            "normed_query_embedding shape : (1, 768)\n",
            "similarities shape : (1, 1000)\n",
            "scores length:  1000\n",
            "sorted_indices_desc length:  1000\n",
            "new shape :  (1, 768)\n",
            "q_vec shape :  (1, 768)\n",
            "Found 1000 candidates\n",
            "vectors shape : (1000, 768)\n",
            "indices shape : (1000,)\n",
            "normed_query_embedding shape : (1, 768)\n",
            "similarities shape : (1, 1000)\n",
            "scores length:  1000\n",
            "sorted_indices_desc length:  1000\n",
            "new shape :  (1, 768)\n",
            "q_vec shape :  (1, 768)\n",
            "Found 1000 candidates\n",
            "vectors shape : (1000, 768)\n",
            "indices shape : (1000,)\n",
            "normed_query_embedding shape : (1, 768)\n",
            "similarities shape : (1, 1000)\n",
            "scores length:  1000\n",
            "sorted_indices_desc length:  1000\n",
            "new shape :  (1, 768)\n",
            "q_vec shape :  (1, 768)\n",
            "Found 1000 candidates\n",
            "vectors shape : (1000, 768)\n",
            "indices shape : (1000,)\n",
            "normed_query_embedding shape : (1, 768)\n",
            "similarities shape : (1, 1000)\n",
            "scores length:  1000\n",
            "sorted_indices_desc length:  1000\n",
            "new shape :  (1, 768)\n",
            "q_vec shape :  (1, 768)\n",
            "Found 1000 candidates\n",
            "vectors shape : (1000, 768)\n",
            "indices shape : (1000,)\n",
            "normed_query_embedding shape : (1, 768)\n",
            "similarities shape : (1, 1000)\n",
            "scores length:  1000\n",
            "sorted_indices_desc length:  1000\n",
            "new shape :  (1, 768)\n",
            "q_vec shape :  (1, 768)\n",
            "Found 1000 candidates\n",
            "vectors shape : (1000, 768)\n",
            "indices shape : (1000,)\n",
            "normed_query_embedding shape : (1, 768)\n",
            "similarities shape : (1, 1000)\n",
            "scores length:  1000\n",
            "sorted_indices_desc length:  1000\n",
            "new shape :  (1, 768)\n",
            "q_vec shape :  (1, 768)\n",
            "Found 1000 candidates\n",
            "vectors shape : (1000, 768)\n",
            "indices shape : (1000,)\n",
            "normed_query_embedding shape : (1, 768)\n",
            "similarities shape : (1, 1000)\n",
            "scores length:  1000\n",
            "sorted_indices_desc length:  1000\n",
            "cosine_context[0] length : 294\n"
          ]
        }
      ],
      "source": [
        "query_embeddings = embed_all_questions(questions[:10])\n",
        "all_som_context = get_som_all(questions[:10], query_embeddings)\n",
        "print(f'som_context[0] length : {len(som_context[0])}')\n",
        "all_cosine_context = get_cosine_all(questions[:10], query_embeddings)\n",
        "print(f'cosine_context[0] length : {len(cosine_context[0])}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(all_som_context))\n",
        "print(len(all_cosine_context))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxULFe4TMFkS",
        "outputId": "4e3ea39b-96d1-49f1-8d4b-b4f92f65f0d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "def create_context_dataframe(questions, all_som_contexts, all_cosine_contexts):\n",
        "  df = pd.DataFrame({\n",
        "      \"question\": questions,\n",
        "      \"som_context\": all_som_contexts,\n",
        "      \"cosine_context\": all_cosine_contexts,\n",
        "  })\n",
        "  return df\n",
        "\n",
        "def save_and_download_context(df, filename=\"wikipedia_context_comparison.csv\"):\n",
        "  df.to_csv(filename, index=False)\n",
        "  files.download(filename)"
      ],
      "metadata": {
        "id": "dibeF5rmMSZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ! Download results to local storage"
      ],
      "metadata": {
        "id": "a5P2U-H1VA6n"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "b7362800",
        "outputId": "eeba8dd2-f9f5-4b46-9bcb-86cc032b60d0"
      },
      "source": [
        "df = create_context_dataframe(questions, all_som_context, all_cosine_context)\n",
        "save_and_download_context(df, \"wikipedia_context_comparison.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6086bdf9-20c3-4372-b157-c2176d2ae6fc\", \"wikipedia_context_comparison.csv\", 30083)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pfmycBYEnuS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vijtmit-aX_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O9sL8JljaYCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eEy0BgpoaYFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0_HEK-f0aYIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ceeqbGrKaYLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ax744HA7aYPQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5e18b491becd444083204cd619f1cbf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b33f3d912c0247c1b30ee40ae68122f2",
              "IPY_MODEL_324bacceff6b43be9ad9c5582eac6739",
              "IPY_MODEL_f158c59b125d422484ea4468307aeaca"
            ],
            "layout": "IPY_MODEL_359a69cdaabb4744a2defa92d0d2895d"
          }
        },
        "b33f3d912c0247c1b30ee40ae68122f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42a71aeaae2d416195ea6a47684a2f27",
            "placeholder": "​",
            "style": "IPY_MODEL_668c85698024412497c3ab2bc6219695",
            "value": "README.md: "
          }
        },
        "324bacceff6b43be9ad9c5582eac6739": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d92f27ed9d3e4f1998ef4224f3ee43d8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b17c655ffea47e88555dc1cb2d4659d",
            "value": 1
          }
        },
        "f158c59b125d422484ea4468307aeaca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59668f7702194cdf912b53ada5ce0832",
            "placeholder": "​",
            "style": "IPY_MODEL_562a90eaaa0c468cbe2048d224b378fb",
            "value": " 3.84k/? [00:00&lt;00:00, 68.7kB/s]"
          }
        },
        "359a69cdaabb4744a2defa92d0d2895d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42a71aeaae2d416195ea6a47684a2f27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "668c85698024412497c3ab2bc6219695": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d92f27ed9d3e4f1998ef4224f3ee43d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "3b17c655ffea47e88555dc1cb2d4659d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59668f7702194cdf912b53ada5ce0832": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "562a90eaaa0c468cbe2048d224b378fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce48574361554d4f9d5af13c79cd2860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66284b979f8645bca3e948bc85e069c6",
              "IPY_MODEL_9a4347855f254ea1b4229a4707d3c5fb",
              "IPY_MODEL_0f539af298d549d996fa74fc34b646dc"
            ],
            "layout": "IPY_MODEL_b960ab39aeb741cda49774271a128924"
          }
        },
        "66284b979f8645bca3e948bc85e069c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a727a6fcb75b4fcdb0a96ba30156d527",
            "placeholder": "​",
            "style": "IPY_MODEL_ece8e766ec2845c4a4e03d138dd3c6c9",
            "value": "dataset_infos.json: "
          }
        },
        "9a4347855f254ea1b4229a4707d3c5fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08c4b69f2af54a1884ecb539b5635e5d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_322bbda86eb64cc5901a3ce48151613e",
            "value": 1
          }
        },
        "0f539af298d549d996fa74fc34b646dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8cf16c34589428798f7e291c7b0eac8",
            "placeholder": "​",
            "style": "IPY_MODEL_06fd12487c634d5b9fc2ba5d53c845bf",
            "value": " 1.29k/? [00:00&lt;00:00, 18.9kB/s]"
          }
        },
        "b960ab39aeb741cda49774271a128924": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a727a6fcb75b4fcdb0a96ba30156d527": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ece8e766ec2845c4a4e03d138dd3c6c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08c4b69f2af54a1884ecb539b5635e5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "322bbda86eb64cc5901a3ce48151613e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d8cf16c34589428798f7e291c7b0eac8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06fd12487c634d5b9fc2ba5d53c845bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}