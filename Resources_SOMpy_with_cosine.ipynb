{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cs67_R-4_u1U"
      },
      "source": [
        "# Content\n",
        "\n",
        "1. Load the cohere wikipedia dataset\n",
        "2. Extract the cohere embeddings for 1000 documents with 768 dimensions\n",
        "3. Select parameters for the SOM by comparing quantization errors\n",
        "4. Train the SOM on the wikipedia document embeddings\n",
        "5. Select the BMUs with at least 1 hit\n",
        "6. Get query\n",
        "7. Embed query into the same dimensions (768)\n",
        "8. Normalize the query vector with the same normalization (var) applied on wikipedia embedding during it's training. (only var normalization has been implemented and available in the SOM library)\n",
        "9. Select the BMU for the query embedding using cosine similarity search (cosine on exp : (1,768) and (89,768))\n",
        "10. Get all embeddings allocated to that BMU as candidate context embeddings\n",
        "11. Get the cosine similarities between the candidate embeddings and the query embedding to select the top k=5 context embeddings. ( exp : (1,768) and (13,768))\n",
        "12. Get the cosine similarity between all document embeddings and the query embedding to select the top k=5 context embeddings. ( exp : (1,768) and (1000,768))\n",
        "13. COMPARE 11 and 12 contexts in terms of\n",
        "*   Accuracy\n",
        "*   Relavance\n",
        "*   Speed of retrieval\n",
        "*   Efficiency of retrieval etc.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GmuTcnWUipLe",
        "outputId": "c7f800bd-371e-4d1b-8190-6df24ae4f8e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-docx in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (1.2.0)\n",
            "Requirement already satisfied: PyMuPDF in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (1.26.3)\n",
            "Requirement already satisfied: pandas in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (2.3.1)\n",
            "Requirement already satisfied: tiktoken in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (0.9.0)\n",
            "Requirement already satisfied: langchain in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (0.3.27)\n",
            "Requirement already satisfied: cohere in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (5.16.1)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from python-docx) (4.14.1)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from python-docx) (6.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from pandas) (2.2.6)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from tiktoken) (2025.7.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from tiktoken) (2.32.4)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from langchain) (0.3.72)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from langchain) (0.4.8)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from langchain) (2.0.42)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from cohere) (2.33.2)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from cohere) (0.28.1)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from cohere) (1.11.1)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from cohere) (0.21.4)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from cohere) (2.32.4.20250611)\n",
            "Requirement already satisfied: httpx-sse==0.4.0 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from cohere) (0.4.0)\n",
            "Requirement already satisfied: httpcore==1.* in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from httpx>=0.21.2->cohere) (1.0.9)\n",
            "Requirement already satisfied: certifi in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from httpx>=0.21.2->cohere) (2025.7.14)\n",
            "Requirement already satisfied: anyio in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from httpx>=0.21.2->cohere) (4.9.0)\n",
            "Requirement already satisfied: idna in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from httpx>=0.21.2->cohere) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.16.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (3.11.1)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
            "Requirement already satisfied: greenlet>=1 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from tokenizers<1,>=0.15->cohere) (0.34.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (1.1.5)\n",
            "Requirement already satisfied: filelock in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2023.9.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.67.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from anyio->httpx>=0.21.2->cohere) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from anyio->httpx>=0.21.2->cohere) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install python-docx PyMuPDF pandas tiktoken langchain cohere"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_Qj-avPiq3l7",
        "outputId": "c3ac9923-d4b0-4ff3-d6a9-7d60bd1fbc1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fsspec==2023.9.2 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (2023.9.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install fsspec==2023.9.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ETn166NWaIZO",
        "outputId": "7ba9c1fd-e92c-4bfd-bdf2-be1f7a9d34db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (4.0.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from datasets) (21.0.0)\n",
            "Requirement already satisfied: pandas in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from datasets) (2.3.1)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: filelock in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from datasets) (2.2.6)\n",
            "Requirement already satisfied: packaging in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: fsspec[http]<=2025.3.0,>=2023.1.0 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from datasets) (2023.9.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from datasets) (0.34.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2025.7.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: six>=1.5 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9rLtxUDs09k7",
        "outputId": "23aa0d1b-f585-43b7-845e-2b3db28f1f39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/GayuniBas2001/SOMPY_sevamoo.git\n",
            "  Cloning https://github.com/GayuniBas2001/SOMPY_sevamoo.git to /tmp/pip-req-build-dnlnwo4_\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/GayuniBas2001/SOMPY_sevamoo.git /tmp/pip-req-build-dnlnwo4_\n",
            "  Resolved https://github.com/GayuniBas2001/SOMPY_sevamoo.git to commit 420bec153a6600857d2160dd1955b2e0f15f799a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: numexpr>=2.5 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from SOMPY==1.1.1) (2.11.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from SOMPY==1.1.1) (2.2.6)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from SOMPY==1.1.1) (1.7.1)\n",
            "Requirement already satisfied: scipy>=0.9 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from SOMPY==1.1.1) (1.15.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from scikit-learn>=0.21->SOMPY==1.1.1) (3.6.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from scikit-learn>=0.21->SOMPY==1.1.1) (1.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install --upgrade git+https://github.com/GayuniBas2001/SOMPY_sevamoo.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfqXNY4z6z9m",
        "outputId": "61b7f526-9c9e-4a6f-879d-f1616ec89ead"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-generativeai in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (0.8.5)\n",
            "Requirement already satisfied: google-api-python-client in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from google-generativeai) (2.177.0)\n",
            "Requirement already satisfied: tqdm in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: protobuf in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from google-generativeai) (2.40.3)\n",
            "Requirement already satisfied: typing-extensions in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from google-generativeai) (4.14.1)\n",
            "Requirement already satisfied: pydantic in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from google-generativeai) (2.11.7)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from pydantic->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.74.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.7.14)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/saleh/SOMpy/evaluation_env/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WUqWdwABiYlA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import io\n",
        "import re\n",
        "import base64\n",
        "import logging\n",
        "import fitz\n",
        "import docx\n",
        "import tiktoken\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import numpy as np\n",
        "import time\n",
        "import sys\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fEz3seM-X5GH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.7.1+cu126\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Add the virtual environment path directly\n",
        "sys.path.insert(0, '/home/saleh/SOMpy/Self-Organizing-Maps/evaluation_env/lib/python3.10/site-packages')\n",
        "\n",
        "# Now try importing torch\n",
        "import torch\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ti63b3NYaCfq"
      },
      "source": [
        "# 01. Loading Wikipedia cohere embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190,
          "referenced_widgets": [
            "1a588cc017224523bfae706ac82e3d9b",
            "e1f3ed85a4894637a22954ab9798409c",
            "751f988c52cd4429b910c505520cdb6f",
            "6c339ae65bec4ffcad7ed7e5341bea45",
            "b1ae6800a5f64addbde168c1c3a6f069",
            "0ce14b200cb3482b82ac55e763c51c3f",
            "45ee321cd90d488bb3b3e3c06a8d2ce8",
            "9b89dde531464cf98678cfff8b7ee85c",
            "e1e900d644d24a128218f56708e732e5",
            "f3fff85d33e54ef9b80ddaf2926f3f77",
            "dcb75619b1454898a585397bd48ea5d0",
            "674066dbd3d1469aa40e98331a678823",
            "ab512cdfc65347659b66b2c974664e96",
            "2cdc61c36367459a8b52e9991e18e6f2",
            "e6c506ecf1084230b25e4b63af492a73",
            "eb0edcf7d43e49ceaf7f4dd550f3eb4b",
            "9cd0a8b9d7444169a55708ab431fc023",
            "4aa829263c6740069462a72452650c4a",
            "244c48b08395443886c2bad51b6dfeae",
            "1c24fbe824514792b73fbab0129eb13e",
            "e8c112acbbbd4d198e93f4cc449a8b24",
            "2a4ce798bca7432f881932fff7ee9def"
          ]
        },
        "collapsed": true,
        "id": "PU8P4hkPabzz",
        "outputId": "66557682-7672-47de-a6af-2c5276a1eced"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:numexpr.utils:Note: detected 96 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n",
            "INFO:numexpr.utils:Note: NumExpr detected 96 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 16.\n",
            "INFO:numexpr.utils:NumExpr defaulting to 16 threads.\n",
            "/home/saleh/SOMpy/Self-Organizing-Maps/evaluation_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "#Load at max 1000 documents + embeddings\n",
        "max_docs = 2000\n",
        "docs_stream = load_dataset(f\"Cohere/wikipedia-22-12-simple-embeddings\", split=\"train\", streaming=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TifuALR6bAEk",
        "outputId": "69a38747-ca47-4c24-9e4f-515d0b9536e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "IterableDataset({\n",
              "    features: ['id', 'title', 'text', 'url', 'wiki_id', 'views', 'paragraph_id', 'langs', 'emb'],\n",
              "    num_shards: 4\n",
              "})"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs_stream"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ARgRAD1BbMRG"
      },
      "outputs": [],
      "source": [
        "docs = []\n",
        "wik_embeddings = []\n",
        "\n",
        "for doc in docs_stream:\n",
        "    docs.append(doc)\n",
        "    wik_embeddings.append(doc['emb'])\n",
        "    if len(docs) >= max_docs:\n",
        "        break\n",
        "\n",
        "wik_embeddings = torch.tensor(wik_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0VVIvDTbV6F",
        "outputId": "e90d6cbf-6a98-4025-9805-dd5ff318c196"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2000, 768])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wik_embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Z7Jxx3GM09ca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1785676/1994228931.py:3: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
            "  np_embeddings = np.array(wik_embeddings)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "np_embeddings = np.array(wik_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLxmFmyo6RFR"
      },
      "source": [
        "# 02. Query Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-b5ItjsdIIr",
        "outputId": "d8f1feb8-57bb-4552-ec9b-2fda84868fd2"
      },
      "outputs": [],
      "source": [
        "import cohere\n",
        "cohere_api_key = \"KMgAyxtG2SjcOkLRvGJpS0ZIYk34RCEKtjs5AMPp\"\n",
        "co = cohere.ClientV2(api_key=cohere_api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHeVMS3Gc2hN"
      },
      "source": [
        "Use cohere API key : KMgAyxtG2SjcOkLRvGJpS0ZIYk34RCEKtjs5AMPp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "rLCNM7Dq6QTU"
      },
      "outputs": [],
      "source": [
        "model = \"multilingual-22-12\" # To get 768 dimensions like in the wikipedia embeddings, we must use this model for the query\n",
        "input_type = \"search_query\"\n",
        "output_dimension = wik_embeddings.shape[1]\n",
        "\n",
        "def embed_prompt(prompt: list,\n",
        "                 model: str = 'multilingual-22-12',\n",
        "                 input_type: str = 'search_query',\n",
        "                 output_dimenion: int = wik_embeddings.shape[1]) -> np.ndarray:\n",
        "\n",
        "    texts = prompt  # Ensure prompt is a list, as co.embed expects a list of texts\n",
        "\n",
        "    res = co.embed(\n",
        "        texts=texts,\n",
        "        model=model,\n",
        "        input_type=input_type,\n",
        "        output_dimension=output_dimension, # Specify the output dimension\n",
        "        embedding_types=[\"float\"],\n",
        "    )\n",
        "\n",
        "    if res.embeddings and res.embeddings.float:\n",
        "        return np.array(res.embeddings.float) # co.embed returns a list of embeddings, one for each text in the input list. If we provide only one prompt, we take the first embedding\n",
        "    else:\n",
        "        raise ValueError(\"Cohere embed API did not return expected embeddings.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ULWSuo92WBvW"
      },
      "outputs": [],
      "source": [
        "questions = [\n",
        "    \"What is the international standard that uses the 24-hour clock format?\",\n",
        "    \"Which three parts make up the Tanakh in Judaism?\",\n",
        "    \"In which three cities was Gotham City filmed for The Dark Knight Rises?\",\n",
        "    \"Against which team did Ronaldo score his famous bicycle-kick goal in the 2018 UEFA Champions League?\",\n",
        "    \"Which German stateâ€™s court ruled on 5 April 2018 that Puigdemont would not be extradited on charges of rebellion?\",\n",
        "    \"What is the voltage range typically used to represent the On state in a logic gate?\",\n",
        "    \"Where is Canada's national capital, where the federal government meets?\",\n",
        "    \"According to the Copenhagen Interpretation, what state is the cat in before the box is opened?\",\n",
        "    \"What gas is identified as the main cause of global warming due to burning fossil fuels?\",\n",
        "    \"Which Indian leader used peaceful tactics including \\\"ahimsa\\\" to lead the freedom movement against British rule?\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlF1l9e5mNf8",
        "outputId": "da35f0df-ce76-42b2-cde1-ea1d782fd818"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.cohere.com/v2/embed \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(10, 768)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "original_query_embeddings = embed_prompt(questions)\n",
        "original_query_embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "W8hgcrDOdK0i"
      },
      "outputs": [],
      "source": [
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PWQvUHqB8ZME"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import tracemalloc\n",
        "import logging\n",
        "\n",
        "# Enable logging if desired\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def benchmark_function(func, *args, **kwargs):\n",
        "    logger.info(f\"Running {func.__name__}...\")\n",
        "\n",
        "    # Start memory tracking\n",
        "    tracemalloc.start()\n",
        "\n",
        "    # Start timing\n",
        "    start_time = time.perf_counter()\n",
        "    result = func(*args, **kwargs)\n",
        "    end_time = time.perf_counter()\n",
        "\n",
        "    # Measure memory usage\n",
        "    current, peak = tracemalloc.get_traced_memory()\n",
        "    tracemalloc.stop()\n",
        "\n",
        "    logger.info(f\"{func.__name__} completed.\")\n",
        "    logger.info(f\"Time taken: {end_time - start_time:.4f} seconds\")\n",
        "    logger.info(f\"Peak memory usage: {peak / 1024:.2f} KB\")\n",
        "\n",
        "    return result, end_time - start_time, peak"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lr6e5gezq3g"
      },
      "source": [
        "# 03. Context Retreival from Reduced Dimensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "PVEi_UxBxnyP"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CACHEDIR=/home/saleh/.cache/matplotlib\n",
            "Using fontManager instance from /home/saleh/.cache/matplotlib/fontlist-v390.json\n"
          ]
        }
      ],
      "source": [
        "from math import sqrt\n",
        "from sompy.sompy import SOMFactory, SOM\n",
        "import itertools\n",
        "from typing import Any, Dict, List, Tuple\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "#cal_quantization_error function is not used in the code. This is to understand how SOM is calculating the qe\n",
        "def cal_quantization_error(sm: SOM, data: np.ndarray) -> float:\n",
        "    bmus, squared_partial = sm.find_bmu(data)\n",
        "    fixed_euclidean_x2 = np.einsum('ij,ij->i', data, data)\n",
        "    distances = np.sqrt(squared_partial + fixed_euclidean_x2)\n",
        "    return np.mean(distances)\n",
        "\n",
        "def train_som_model(np_embeddings, mapsizes, normalizations, initializations, lattices, neighborhoods, trainings, names, rough_len, finetune_len):\n",
        "    som_fac = SOMFactory()\n",
        "    sm = som_fac.build(np_embeddings, mapsize=mapsizes, normalization=normalizations, initialization=initializations, lattice=lattices, neighborhood=neighborhoods, training=trainings, name=names)\n",
        "    sm.train(n_job=1, verbose=False, train_rough_len=rough_len, train_finetune_len=finetune_len)\n",
        "    topographic_error = sm.calculate_topographic_error()\n",
        "    quantization_error = sm.quant_error_history[-1]\n",
        "    print(f\"Topographic error = {topographic_error}; Quantization error = {quantization_error}\")\n",
        "    return sm\n",
        "\n",
        "def find_closest_hit_per_bmu(sm):\n",
        "    chunk_bmu_indices = sm._bmu[0].astype(int) #\n",
        "    chunk_bmu_qe = sm._bmu[1] #qe between the chunk and it's bmu\n",
        "    data = sm._data #the chunk embeddings (already normalized)\n",
        "\n",
        "    closest_indices = np.full(sm.codebook.nnodes, np.nan)\n",
        "    min_errors = np.full(sm.codebook.nnodes, np.inf)\n",
        "\n",
        "    for idx, (bmu, err) in enumerate(zip(chunk_bmu_indices, chunk_bmu_qe)):\n",
        "        if err < min_errors[bmu]:\n",
        "            min_errors[bmu] = err\n",
        "            closest_indices[bmu] = idx\n",
        "\n",
        "    bmu_first_hit_vectors = [data[int(i)] if not np.isnan(i) else None for i in closest_indices]\n",
        "    return closest_indices, bmu_first_hit_vectors\n",
        "\n",
        "def cosine_bmu_retrieve(normed_query_embedding, som_model, bmu_hit_vectors_with_indices, top_k: int = 5): #Here we take 5 best matiching BMUs (units with at least 1 hit) for a query\n",
        "    filtered = [(i, v) for i, v in bmu_hit_vectors_with_indices if v is not None and not np.isnan(v).any()]\n",
        "    if len(filtered) == 0:\n",
        "        raise ValueError(\"No valid BMU vectors available for similarity comparison.\")\n",
        "\n",
        "    indices, vectors = zip(*filtered)\n",
        "    vectors = np.array(vectors)\n",
        "    indices = np.array(indices)\n",
        "    print('number of hit vectors: ',len(indices))\n",
        "\n",
        "    similarities = cosine_similarity(normed_query_embedding, vectors)\n",
        "    sorted_indices_desc = np.argsort(similarities[0])[::-1]\n",
        "    top_k_indices = sorted_indices_desc[:top_k] #Indices from the similarity array\n",
        "    print(f\"top_k_indices : {top_k_indices}\")\n",
        "    selected_bmu_index = indices[top_k_indices] #Indices of the actual BMUs\n",
        "    print(f\"selected_bmu_index : {selected_bmu_index}\")\n",
        "    return selected_bmu_index\n",
        "\n",
        "def cosine_context_similarity(normed_query_embedding, candidate_vectors_with_indices, top_k: int = 5):\n",
        "    indices, vectors = zip(*candidate_vectors_with_indices)\n",
        "    vectors = np.array(vectors)\n",
        "    logger.info(f\"vectors shape : {vectors.shape}\") #(cand_count,768)\n",
        "    indices = np.array(indices)\n",
        "    logger.info(f\"indices shape : {indices.shape}\") #(cand_count,)\n",
        "    logger.info(f\"normed_query_embedding shape : {normed_query_embedding.shape}\") #(1,768)\n",
        "    similarities = cosine_similarity(normed_query_embedding, vectors)\n",
        "    logger.info(f\"similarities shape : {similarities.shape}\") #(1, valid)\n",
        "    return similarities\n",
        "\n",
        "def normalize_reshape (query_embedding, sm):\n",
        "    vec = query_embedding.reshape(1, -1)\n",
        "    normed_query_embedding = sm._normalizer.normalize_by(sm.data_raw, vec)\n",
        "    logger.info(f\"new shape : \",vec.shape)\n",
        "    return normed_query_embedding\n",
        "\n",
        "def get_som_context(\n",
        "    query_embedding: np.ndarray,\n",
        "    som_model,\n",
        "    bmu_hit_vectors_with_indices,\n",
        "    chunks,\n",
        "    rerank_method: str = 'cosine',\n",
        "    top_k: int = 5,\n",
        "    bmu_k: int = 5\n",
        "):\n",
        "  q_vec = normalize_reshape(query_embedding, som_model)\n",
        "  logger.info(f\"q_vec shape : \",q_vec.shape)\n",
        "  q_bmus = cosine_bmu_retrieve(q_vec, som_model, bmu_hit_vectors_with_indices, bmu_k)\n",
        "  logger.info(f\"q_bmus to use : \",q_bmus)\n",
        "\n",
        "  chunk_bmu_indices = som_model._bmu[0].astype(int)\n",
        "\n",
        "  q_bmus_set = set(q_bmus)\n",
        "  candidates_emb = [(i, chunks[i]['emb']) for i, bmu_index in enumerate(chunk_bmu_indices) if bmu_index in q_bmus_set]\n",
        "\n",
        "  logger.info(f\"Found {len(candidates_emb)} candidates\")\n",
        "\n",
        "  # d) Rerank based on the specified method\n",
        "  if rerank_method == 'cosine':\n",
        "      scores = cosine_context_similarity(q_vec, candidates_emb, top_k)[0]\n",
        "      sorted_indices_desc = np.argsort(scores)[::-1] # indices of 20 candidates, not the actual indices\n",
        "\n",
        "      top_k_chunk_indices = [candidates_emb[i][0] for i in sorted_indices_desc[:top_k]]\n",
        "\n",
        "      logger.info('top_k_chunk_indices : ', top_k_chunk_indices)\n",
        "\n",
        "      top_k_indices = top_k_chunk_indices\n",
        "\n",
        "      context = [chunks[i]['text'] for i in top_k_indices]\n",
        "      context_scores = scores[sorted_indices_desc[:top_k]]\n",
        "\n",
        "      return context, context_scores\n",
        "\n",
        "  else:\n",
        "      raise ValueError(f\"Unknown rerank_method: {rerank_method}. Choose 'cosine' or 'quantization_error'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "IqXFNxQVOPdq"
      },
      "outputs": [],
      "source": [
        "results = [{'mapsize': (10, 10), 'normalization': 'var', 'initialization': 'random', 'lattice': 'hexa', 'neighborhood': 'gaussian', 'training': 'batch', 'name': 'som1', 'rough_len': 800, 'finetune_len': 100, 'test_index': 0, 'topographic_error': np.float64(0.092), 'quantization_error': np.float64(24.17343805953296)}, {'mapsize': (10, 10), 'normalization': 'var', 'initialization': 'random', 'lattice': 'hexa', 'neighborhood': 'gaussian', 'training': 'seq', 'name': 'som1', 'rough_len': 800, 'finetune_len': 100, 'test_index': 1, 'topographic_error': np.float64(0.147), 'quantization_error': np.float64(23.95357177963876)}, {'mapsize': (10, 10), 'normalization': 'var', 'initialization': 'random', 'lattice': 'rect', 'neighborhood': 'gaussian', 'training': 'batch', 'name': 'som1', 'rough_len': 800, 'finetune_len': 100, 'test_index': 2, 'topographic_error': np.float64(0.399), 'quantization_error': np.float64(23.053306262876312)}, {'mapsize': (10, 10), 'normalization': 'var', 'initialization': 'random', 'lattice': 'rect', 'neighborhood': 'gaussian', 'training': 'seq', 'name': 'som1', 'rough_len': 800, 'finetune_len': 100, 'test_index': 3, 'topographic_error': np.float64(0.423), 'quantization_error': np.float64(23.07128526327146)}, {'mapsize': (10, 10), 'normalization': 'var', 'initialization': 'pca', 'lattice': 'hexa', 'neighborhood': 'gaussian', 'training': 'batch', 'name': 'som1', 'rough_len': 800, 'finetune_len': 100, 'test_index': 4, 'topographic_error': np.float64(0.119), 'quantization_error': np.float64(23.89813955987797)}, {'mapsize': (10, 10), 'normalization': 'var', 'initialization': 'pca', 'lattice': 'hexa', 'neighborhood': 'gaussian', 'training': 'seq', 'name': 'som1', 'rough_len': 800, 'finetune_len': 100, 'test_index': 5, 'topographic_error': np.float64(0.119), 'quantization_error': np.float64(23.89813955987797)}, {'mapsize': (10, 10), 'normalization': 'var', 'initialization': 'pca', 'lattice': 'rect', 'neighborhood': 'gaussian', 'training': 'batch', 'name': 'som1', 'rough_len': 800, 'finetune_len': 100, 'test_index': 6, 'topographic_error': np.float64(0.404), 'quantization_error': np.float64(23.062587304824785)}, {'mapsize': (10, 10), 'normalization': 'var', 'initialization': 'pca', 'lattice': 'rect', 'neighborhood': 'gaussian', 'training': 'seq', 'name': 'som1', 'rough_len': 800, 'finetune_len': 100, 'test_index': 7, 'topographic_error': np.float64(0.404), 'quantization_error': np.float64(23.062587304824785)}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "-rOpUiwjotdQ"
      },
      "outputs": [],
      "source": [
        "test_index = 6\n",
        "test_case = results[test_index]\n",
        "\n",
        "def reduced_dim_retreival(\n",
        "    np_embeddings,\n",
        "    original_query_embeddings,\n",
        "    test_case,\n",
        "    sm\n",
        "):\n",
        "  som_contexts_scores = []\n",
        "  map_size = sm.codebook.nnodes\n",
        "\n",
        "  bmu_first_hit_indices, bmu_first_hit_vectors = find_closest_hit_per_bmu(sm) #index of the first hit chunk and it's vector\n",
        "\n",
        "  bmu_hit_vectors_with_indices = [(i, v) for i,v in enumerate(bmu_first_hit_vectors)] #idex of the bmu (to represent the cluster) and the vector of the chunk\n",
        "\n",
        "  for q in original_query_embeddings:\n",
        "    print('q shape', q.shape)\n",
        "    som_context, som_context_score = get_som_context(q, sm, bmu_hit_vectors_with_indices, docs)\n",
        "    som_contexts_scores.append((som_context, som_context_score))\n",
        "\n",
        "  return som_contexts_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LN67-A-H1jt1"
      },
      "source": [
        "# 04. Context Retreival from Original Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "G-FF2BGya39i"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "def get_cosine_context(query_embeddings: np.ndarray, chunks, top_k: int = 5):\n",
        "    vectors = np.array([chunk['emb'] for chunk in chunks])\n",
        "    texts = [chunk['text'] for chunk in chunks]\n",
        "\n",
        "    #### Normalizing ####\n",
        "    scaler = StandardScaler()\n",
        "    vectors = scaler.fit_transform(vectors)\n",
        "    query_embeddings = scaler.transform(query_embeddings)\n",
        "    ####\n",
        "\n",
        "    cosine_contexts_scores = []\n",
        "    similarities = cosine_similarity(query_embeddings, vectors)  # shape: (n_queries, n_chunks)\n",
        "\n",
        "    for query_sim in similarities:  # shape: (n_chunks,)\n",
        "        # Get top_k efficiently\n",
        "        top_k_indices = np.argpartition(-query_sim, top_k)[:top_k]\n",
        "        top_k_indices = top_k_indices[np.argsort(-query_sim[top_k_indices])]\n",
        "\n",
        "        context = [texts[i] for i in top_k_indices]\n",
        "        context_score = [query_sim[i] for i in top_k_indices]\n",
        "        cosine_contexts_scores.append((context, context_score))\n",
        "\n",
        "    return cosine_contexts_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rO3TDCV2POo0"
      },
      "source": [
        "# 05. Running the Functions with Resource Calculations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FR7TliIGOoBl",
        "outputId": "9a25a9a0-7b23-4e79-f1c5-bfc765259d10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rough length: 223\n",
            "Finetune length: 894\n"
          ]
        }
      ],
      "source": [
        "# Calculate train lengths\n",
        "rough_len = int(5 * sqrt(len(np_embeddings)))\n",
        "finetune_len = int(20 * sqrt(len(np_embeddings)))\n",
        "print(f\"Rough length: {rough_len}\")\n",
        "print(f\"Finetune length: {finetune_len}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZpf4tsOq66w",
        "outputId": "e4e26d3e-67b9-4810-d9df-4b3e54e4eddb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running train_som_model...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sm, train_time, train_mem \u001b[38;5;241m=\u001b[39m \u001b[43mbenchmark_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_som_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_case\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmapsize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#10,10\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_case\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnormalization\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#var\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpca\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#['random', 'pca']\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_case\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlattice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#['rect', 'hexa']\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_case\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mneighborhood\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#['gaussian', 'bubble']\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_case\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_case\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrough_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfinetune_len\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mðŸ§  SOM Training Benchmark:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_som_model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m sec, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_mem\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1024\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m KB peak memory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn[18], line 17\u001b[0m, in \u001b[0;36mbenchmark_function\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Start timing\u001b[39;00m\n\u001b[1;32m     16\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m---> 17\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Measure memory usage\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[19], line 17\u001b[0m, in \u001b[0;36mtrain_som_model\u001b[0;34m(np_embeddings, mapsizes, normalizations, initializations, lattices, neighborhoods, trainings, names, rough_len, finetune_len)\u001b[0m\n\u001b[1;32m     15\u001b[0m som_fac \u001b[38;5;241m=\u001b[39m SOMFactory()\n\u001b[1;32m     16\u001b[0m sm \u001b[38;5;241m=\u001b[39m som_fac\u001b[38;5;241m.\u001b[39mbuild(np_embeddings, mapsize\u001b[38;5;241m=\u001b[39mmapsizes, normalization\u001b[38;5;241m=\u001b[39mnormalizations, initialization\u001b[38;5;241m=\u001b[39minitializations, lattice\u001b[38;5;241m=\u001b[39mlattices, neighborhood\u001b[38;5;241m=\u001b[39mneighborhoods, training\u001b[38;5;241m=\u001b[39mtrainings, name\u001b[38;5;241m=\u001b[39mnames)\n\u001b[0;32m---> 17\u001b[0m \u001b[43msm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_job\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_rough_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrough_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_finetune_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinetune_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m topographic_error \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mcalculate_topographic_error()\n\u001b[1;32m     19\u001b[0m quantization_error \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mquant_error_history[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
            "File \u001b[0;32m~/SOMpy/evaluation_env/lib/python3.10/site-packages/sompy/decorators.py:11\u001b[0m, in \u001b[0;36mtimeit.<locals>.wrap.<locals>.wrapped_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)  \u001b[38;5;66;03m# keeps the f.__name__ outside the wrapper\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     10\u001b[0m     t0 \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m---> 11\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     ts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(time() \u001b[38;5;241m-\u001b[39m t0, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     14\u001b[0m     title \u001b[38;5;241m=\u001b[39m alternative_title \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
            "File \u001b[0;32m~/SOMpy/evaluation_env/lib/python3.10/site-packages/sompy/sompy.py:250\u001b[0m, in \u001b[0;36mSOM.train\u001b[0;34m(self, n_job, shared_memory, verbose, train_rough_len, train_rough_radiusin, train_rough_radiusfin, train_finetune_len, train_finetune_radiusin, train_finetune_radiusfin, train_len_factor, maxtrainlen)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcodebook\u001b[38;5;241m.\u001b[39mpca_linear_initialization(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data)\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrough_train(njob\u001b[38;5;241m=\u001b[39mn_job, shared_memory\u001b[38;5;241m=\u001b[39mshared_memory, trainlen\u001b[38;5;241m=\u001b[39mtrain_rough_len,\n\u001b[1;32m    249\u001b[0m                  radiusin\u001b[38;5;241m=\u001b[39mtrain_rough_radiusin, radiusfin\u001b[38;5;241m=\u001b[39mtrain_rough_radiusfin,trainlen_factor\u001b[38;5;241m=\u001b[39mtrain_len_factor,maxtrainlen\u001b[38;5;241m=\u001b[39mmaxtrainlen)\n\u001b[0;32m--> 250\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinetune_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnjob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_job\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshared_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshared_memory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainlen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_finetune_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mradiusin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_finetune_radiusin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradiusfin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_finetune_radiusfin\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrainlen_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_len_factor\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmaxtrainlen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxtrainlen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m logging\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m --------------------------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    254\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Final quantization error: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bmu[\u001b[38;5;241m1\u001b[39m]))\n",
            "File \u001b[0;32m~/SOMpy/evaluation_env/lib/python3.10/site-packages/sompy/sompy.py:310\u001b[0m, in \u001b[0;36mSOM.finetune_train\u001b[0;34m(self, njob, shared_memory, trainlen, radiusin, radiusfin, trainlen_factor, maxtrainlen)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m#print(\"maxtrainlen %d\",maxtrainlen)\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m#lbugnon: add trainlen_factor\u001b[39;00m\n\u001b[1;32m    307\u001b[0m trainlen\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(trainlen_factor\u001b[38;5;241m*\u001b[39mtrainlen)\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batchtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainlen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradiusin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradiusfin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnjob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshared_memory\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/SOMpy/evaluation_env/lib/python3.10/site-packages/sompy/sompy.py:342\u001b[0m, in \u001b[0;36mSOM._batchtrain\u001b[0;34m(self, trainlen, radiusin, radiusfin, njob, shared_memory)\u001b[0m\n\u001b[1;32m    339\u001b[0m t1 \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m    340\u001b[0m neighborhood \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneighborhood\u001b[38;5;241m.\u001b[39mcalculate(\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distance_matrix, radius[i], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcodebook\u001b[38;5;241m.\u001b[39mnnodes)\n\u001b[0;32m--> 342\u001b[0m bmu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_bmu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnjb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnjob\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcodebook\u001b[38;5;241m.\u001b[39mmatrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_codebook_voronoi(data, bmu,\n\u001b[1;32m    344\u001b[0m                                                     neighborhood)\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# compute full squared distances\u001b[39;00m\n",
            "File \u001b[0;32m~/SOMpy/evaluation_env/lib/python3.10/site-packages/sompy/decorators.py:11\u001b[0m, in \u001b[0;36mtimeit.<locals>.wrap.<locals>.wrapped_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)  \u001b[38;5;66;03m# keeps the f.__name__ outside the wrapper\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     10\u001b[0m     t0 \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m---> 11\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     ts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(time() \u001b[38;5;241m-\u001b[39m t0, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     14\u001b[0m     title \u001b[38;5;241m=\u001b[39m alternative_title \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
            "File \u001b[0;32m~/SOMpy/evaluation_env/lib/python3.10/site-packages/sompy/sompy.py:404\u001b[0m, in \u001b[0;36mSOM.find_bmu\u001b[0;34m(self, input_matrix, njb, nth)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmin\u001b[39m((part\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mdlen \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m njb, dlen)\n\u001b[1;32m    403\u001b[0m chunks \u001b[38;5;241m=\u001b[39m [input_matrix[row_chunk(i):col_chunk(i)] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(njb)]\n\u001b[0;32m--> 404\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_bmu_finder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodebook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m pool\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    406\u001b[0m pool\u001b[38;5;241m.\u001b[39mjoin()\n",
            "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
            "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
            "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "sm, train_time, train_mem = benchmark_function(\n",
        "    train_som_model,\n",
        "    np_embeddings,\n",
        "    test_case['mapsize'], #10,10\n",
        "    test_case['normalization'], #var\n",
        "    'pca', #['random', 'pca']\n",
        "    test_case['lattice'], #['rect', 'hexa']\n",
        "    test_case['neighborhood'], #['gaussian', 'bubble']\n",
        "    test_case['training'],\n",
        "    test_case['name'],\n",
        "    rough_len,\n",
        "    finetune_len\n",
        ")\n",
        "\n",
        "print(\"\\nðŸ§  SOM Training Benchmark:\")\n",
        "print(f\"train_som_model: {train_time:.4f} sec, {train_mem / 1024:.2f} KB peak memory\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8nbLFwhJy2v3",
        "outputId": "44105c09-25e8-457a-f2b9-04de2b8e3921"
      },
      "outputs": [],
      "source": [
        "# Run and benchmark reduced_dim_retreival\n",
        "som_contexts_scores, time1, mem1 = benchmark_function(\n",
        "    reduced_dim_retreival, np_embeddings, original_query_embeddings, test_case, sm\n",
        ")\n",
        "\n",
        "# Run and benchmark get_cosine_context\n",
        "cosine_contexts_scores, time2, mem2 = benchmark_function(\n",
        "    get_cosine_context, original_query_embeddings, docs\n",
        ")\n",
        "\n",
        "# Print final comparison\n",
        "print(\"\\nðŸ” Performance Comparison:\")\n",
        "print(f\"reduced_dim_retreival: {time1:.4f} sec, {mem1 / 1024:.2f} KB peak memory\")\n",
        "print(f\"get_cosine_context:     {time2:.4f} sec, {mem2 / 1024:.2f} KB peak memory\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HoooLN948d-K",
        "outputId": "04037545-37b3-43ab-cc79-030893bdf5a4"
      },
      "outputs": [],
      "source": [
        "for r in som_contexts_scores:\n",
        "  # print(f\"[{r[1]:.3f}]\\t{r[0]}\")\n",
        "  for txt, score in zip(r[0],r[1]):\n",
        "    print(f\"[{score:.3f}]\\t{txt}\")\n",
        "  print('\\n\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DIMxAPHdy2sk",
        "outputId": "4a09871e-5022-406b-9c12-683df2f38475"
      },
      "outputs": [],
      "source": [
        "for r in cosine_contexts_scores:\n",
        "  # print(f\"[{r[1]:.3f}]\\t{r[0]}\")\n",
        "  for txt, score in zip(r[0],r[1]):\n",
        "    print(f\"[{score:.3f}]\\t{txt}\")\n",
        "  print('\\n\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqvVbywa7Gnc"
      },
      "source": [
        "# 06. Evaluating Results with Confusion Metrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7NYx6VvcPqa"
      },
      "source": [
        "![cm.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mbgqaiAX5VO"
      },
      "source": [
        "**In sklearn,**\n",
        "\n",
        "|                         | **Predicted Negative (0)** | **Predicted Positive (1)** |\n",
        "| ----------------------- | -------------------------- | -------------------------- |\n",
        "| **Actual Negative (0)** | True Negative (TN)         | False Positive (FP)        |\n",
        "| **Actual Positive (1)** | False Negative (FN)        | True Positive (TP)         |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obYYhtSccUK_"
      },
      "source": [
        "Predicted Values -> Retreived Context (From either reduced or original embeddings)\n",
        "- Positive : Context contains the asnwer\n",
        "- Negative : Context does not contain the answer\n",
        "\n",
        "Actual Values -> The content of the RAG knowledge base (KB)\n",
        "- Positive : KB contains the answer\n",
        "- Negative : KB does not contain the answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BY62ULg5MNJ",
        "outputId": "a31d3c33-9947-4cf2-a8a7-759a9a9fdca7"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "from getpass import getpass\n",
        "import time\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "\n",
        "# Set up your Gemini API key\n",
        "genai.configure(api_key=getpass(\"Enter your Gemini API key: \"))\n",
        "\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "\n",
        "def query_llm_contains_answer(question, answer, context, max_retries=3):\n",
        "    prompt = (\n",
        "        f\"Question: {question}\\n\"\n",
        "        f\"Answer: {answer}\\n\"\n",
        "        f\"Context: {context}\\n\\n\"\n",
        "        \"Does the context clearly contain or imply the correct answer to the question?\\n\"\n",
        "        \"Answer only with 'Yes' or 'No'.\"\n",
        "    )\n",
        "\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            response = model.generate_content(prompt)\n",
        "            reply = response.text.strip()\n",
        "            return \"Yes\" if \"yes\" in reply.lower() else \"No\"\n",
        "        except Exception as e:\n",
        "            print(f\"[Retry {attempt+1}] Gemini call failed: {e}\")\n",
        "            time.sleep(1)\n",
        "\n",
        "    return \"No\"  # Fail-safe\n",
        "\n",
        "def evaluate_context_retrieval(q_list, a_list, reduced_contexts, original_contexts):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "        qa_list: List of tuples (question, answer)\n",
        "        reduced_contexts: List of strings (retrieved contexts from REDUCED SOM)\n",
        "        original_contexts: List of strings (retrieved contexts from ORIGINAL full embeddings)\n",
        "\n",
        "    Returns:\n",
        "        DataFrame containing actual, reduced_pred, and original_pred values\n",
        "        And confusion matrix results for both REDUCED and ORIGINAL\n",
        "    \"\"\"\n",
        "\n",
        "    actual = []\n",
        "    reduced_pred = []\n",
        "    original_pred = []\n",
        "\n",
        "    for question, answer, reduced_ctx, original_ctx in zip(q_list, a_list, reduced_contexts, original_contexts):\n",
        "        # Determine Actual: 1 if answer is present, 0 if no answer\n",
        "        act = 1 if answer and answer.strip() else 0\n",
        "        actual.append(act)\n",
        "\n",
        "        # # Prediction for REDUCED\n",
        "        # if act == 1:\n",
        "        #     reduced_pred.append(1 if answer.lower() in reduced_ctx.lower() else 0)\n",
        "        #     original_pred.append(1 if answer.lower() in original_ctx.lower() else 0)\n",
        "        # else:\n",
        "        #     reduced_pred.append(0)  # no answer expected, predicted negative\n",
        "        #     original_pred.append(0)\n",
        "\n",
        "        if act == 1:\n",
        "            # Use LLM to judge if context contains the answer\n",
        "            reduced_response = query_llm_contains_answer(question, answer, reduced_ctx)\n",
        "            print(f\"Respose Received\")\n",
        "            print(f\"Reduced Context : {reduced_ctx}\")\n",
        "            print(\"Waiting 30 seconds to avoid rate limits...\")\n",
        "            time.sleep(30)  # Wait for 30 seconds to average 2 requests per minute\n",
        "\n",
        "            reduced_pred.append(1 if reduced_response == \"Yes\" else 0)\n",
        "\n",
        "            original_response = query_llm_contains_answer(question, answer, original_ctx)\n",
        "            print(f\"Respose Received\")\n",
        "            print(f\"Original Context : {original_ctx}\")\n",
        "            print(\"Waiting 30 seconds to avoid rate limits...\")\n",
        "            time.sleep(30)  # Wait for 30 seconds to average 2 requests per minute\n",
        "\n",
        "            original_pred.append(1 if original_response == \"Yes\" else 0)\n",
        "        else:\n",
        "            # No answer expected\n",
        "            reduced_pred.append(0)\n",
        "            original_pred.append(0)\n",
        "\n",
        "    # Create a DataFrame for analysis\n",
        "    df = pd.DataFrame({\n",
        "        'Question': [q for (q, a) in zip(q_list, a_list)],\n",
        "        'Answer': [a for (q, a) in zip(q_list, a_list)],\n",
        "        'Actual': actual,\n",
        "        'Reduced_Predicted': reduced_pred,\n",
        "        'Original_Predicted': original_pred\n",
        "    })\n",
        "\n",
        "    # Confusion Matrices\n",
        "    reduced_cm = confusion_matrix(actual, reduced_pred)\n",
        "    original_cm = confusion_matrix(actual, original_pred)\n",
        "\n",
        "    print(\"Confusion Matrix for REDUCED retreival:\")\n",
        "    print(reduced_cm)\n",
        "    print(\"\\nConfusion Matrix for ORIGINAL retreival:\")\n",
        "    print(original_cm)\n",
        "\n",
        "    reduced_metrics = {\n",
        "        'Precision': precision_score(actual, reduced_pred),\n",
        "        'Recall': recall_score(actual, reduced_pred),\n",
        "        'F1 Score': f1_score(actual, reduced_pred)\n",
        "    }\n",
        "\n",
        "    original_metrics = {\n",
        "        'Precision': precision_score(actual, original_pred),\n",
        "        'Recall': recall_score(actual, original_pred),\n",
        "        'F1 Score': f1_score(actual, original_pred)\n",
        "    }\n",
        "\n",
        "    return df, reduced_cm, original_cm, reduced_metrics, original_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGNwlL5EDKiQ"
      },
      "source": [
        "- Use gemini API key 01 : AIzaSyBny44J9L1at51yIQwgvQWNjnhBMRJlMN0\n",
        "- Use gemini API key 02 : AIzaSyCz6IcWf8v3rGDmORjBAxwa2w4YCTIes64\n",
        "- Use gemini API key 03 : AIzaSyAI_7X6j91J3GqboJIeAbkeg_NEsoafOTw\n",
        "- Use gemini API key 04 : AIzaSyCz6IcWf8v3rGDmORjBAxwa2w4YCTIes64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzPXCRq1xMMH"
      },
      "outputs": [],
      "source": [
        "questions = [\n",
        "    \"What is the international standard that uses the 24-hour clock format?\",\n",
        "    \"Which three parts make up the Tanakh in Judaism?\",\n",
        "    \"In which three cities was Gotham City filmed for The Dark Knight Rises?\",\n",
        "    \"Against which team did Ronaldo score his famous bicycle-kick goal in the 2018 UEFA Champions League?\",\n",
        "    \"Which German stateâ€™s court ruled on 5 April 2018 that Puigdemont would not be extradited on charges of rebellion?\",\n",
        "    \"What is the voltage range typically used to represent the On state in a logic gate?\",\n",
        "    \"Where is Canada's national capital, where the federal government meets?\",\n",
        "    \"According to the Copenhagen Interpretation, what state is the cat in before the box is opened?\",\n",
        "    \"What gas is identified as the main cause of global warming due to burning fossil fuels?\",\n",
        "    \"Which Indian leader used peaceful tactics including \\\"ahimsa\\\" to lead the freedom movement against British rule?\"\n",
        "]\n",
        "\n",
        "answers = [\n",
        "    \"ISO 8601\",\n",
        "    \"Torah, Nevi'im, and Ketuvim\",\n",
        "    \"Pittsburgh, Pennsylvania; New York City, New York; and Los Angeles, California\",\n",
        "    \"Juventus\",\n",
        "    \"Schleswig-Holstein\",\n",
        "    \"3.5 to 5 volts\",\n",
        "    \"Ottawa\",\n",
        "    \"Both dead and alive\",\n",
        "    \"Carbon dioxide\",\n",
        "    \"Mahatma Gandhi\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ezs-MprJxMQa",
        "outputId": "aff03b53-5f73-46ba-f554-240996177005"
      },
      "outputs": [],
      "source": [
        "df, reduced_cm, original_cm, reduced_metrics, original_metrics = evaluate_context_retrieval(questions, answers, som_contexts_scores, cosine_contexts_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "NFrTj0mjxMYB",
        "outputId": "d9f072ec-5406-44a0-94c9-c9867e1204e2"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqqdqPPlbGFk",
        "outputId": "c7358c35-5cf1-4e40-c9dc-a38b5f0977eb"
      },
      "outputs": [],
      "source": [
        "print(\"Reduced Confusion Matrix:\")\n",
        "print(reduced_cm)\n",
        "print(\"\\nOriginal Confusion Matrix:\")\n",
        "print(original_cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BY1bOXWybGSJ",
        "outputId": "83f014a3-4dba-4142-d2b1-8cfdb0024c16"
      },
      "outputs": [],
      "source": [
        "print(\"Reduced Metrics:\")\n",
        "print(reduced_metrics)\n",
        "print(\"\\nOriginal Metrics:\")\n",
        "print(original_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHTOcTOLBZNt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCnBJptIEoiR"
      },
      "source": [
        "# 07. Evaluating Results with ROC curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrfBb1cSEgUA"
      },
      "source": [
        "## Chunk-level ROC: Measures how well the model ranks individual chunks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "BiNOM1Q4bGXk",
        "outputId": "df759ca1-0355-4d9d-8bf3-b67f2dbbfa85"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example lists:\n",
        "all_labels = []  # 1 if chunk contains answer, 0 otherwise\n",
        "all_scores = []  # similarity score of the chunk\n",
        "\n",
        "# Loop through queries\n",
        "for q_index, (question, answer, (top_chunks, scores)) in enumerate(zip(questions, answers, som_contexts_scores)):\n",
        "    # print(f'top_chunks : {len(top_chunks)}')\n",
        "    # print(f'scores : {scores}')\n",
        "    for chunk, score in zip(top_chunks, scores):\n",
        "        label = 1 if answer.lower() in chunk.lower() else 0  # or use LLM judgment\n",
        "        all_labels.append(label)\n",
        "        all_scores.append(score)\n",
        "\n",
        "# Compute ROC\n",
        "fpr, tpr, thresholds = roc_curve(all_labels, all_scores)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve - Context Retrieval\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "EtefoaCnbGeI",
        "outputId": "143d6a92-be66-45b9-cf1f-0b68ea5fb271"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example lists:\n",
        "all_labels = []  # 1 if chunk contains answer, 0 otherwise\n",
        "all_scores = []  # similarity score of the chunk\n",
        "\n",
        "# Loop through queries\n",
        "for q_index, (question, answer, (top_chunks, scores)) in enumerate(zip(questions, answers, cosine_contexts_scores)):\n",
        "    # print(f'top_chunks : {len(top_chunks)}')\n",
        "    # print(f'scores : {scores}')\n",
        "    for chunk, score in zip(top_chunks, scores):\n",
        "        label = 1 if answer.lower() in chunk.lower() else 0  # or use LLM judgment\n",
        "        all_labels.append(label)\n",
        "        all_scores.append(score)\n",
        "\n",
        "# Compute ROC\n",
        "fpr, tpr, thresholds = roc_curve(all_labels, all_scores)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve - Context Retrieval\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjPjxfiJE5fV"
      },
      "source": [
        "## Question-level ROC (with averaged scores): Measures how well the system retrieves useful overall context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "YJvBabGeFlNq",
        "outputId": "b5bfbbe8-ec51-4561-f3d2-b63fbb3b2833"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "avg_scores = []\n",
        "labels = df['Reduced_Predicted']\n",
        "\n",
        "for q_index, (question, answer, (top_chunks, scores)) in enumerate(zip(questions, answers, som_contexts_scores)):\n",
        "    avg_score = sum(scores) / len(scores)\n",
        "    # contains_answer = any(answer.lower() in c.lower() for c in top_chunks)  # or use LLM for better check\n",
        "    avg_scores.append(avg_score)\n",
        "    # labels.append(1 if contains_answer else 0)\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(labels, avg_scores)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve - Context Retrieval\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "FezWXXSJxMgj",
        "outputId": "88d59b03-f9ba-44be-8ca2-06c07acf771e"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "avg_scores = []\n",
        "labels = df['Original_Predicted']\n",
        "\n",
        "for q_index, (question, answer, (top_chunks, scores)) in enumerate(zip(questions, answers, cosine_contexts_scores)):\n",
        "    avg_score = sum(scores) / len(scores)\n",
        "    # contains_answer = any(answer.lower() in c.lower() for c in top_chunks)  # or use LLM for better check\n",
        "    avg_scores.append(avg_score)\n",
        "    # labels.append(1 if contains_answer else 0)\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(labels, avg_scores)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve - Context Retrieval\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gpqewOXE7yD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVsIrem5E73P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyVfL45kE78E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ApV7mPxE8AK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfdTkM89E8Cm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYcmXjk-E8Jj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQXenw3CVV8z"
      },
      "outputs": [],
      "source": [
        "sm = train_som_model(\n",
        "        np_embeddings,\n",
        "        test_case['mapsize'],\n",
        "        test_case['normalization'],\n",
        "        test_case['initialization'],\n",
        "        test_case['lattice'],\n",
        "        test_case['neighborhood'],\n",
        "        test_case['training'],\n",
        "        test_case['name'],\n",
        "        test_case['rough_len'],\n",
        "        test_case['finetune_len']\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3Bwhi2Wd6Kq9",
        "outputId": "4d507339-79ad-4213-aeda-470d9a993bda"
      },
      "outputs": [],
      "source": [
        "som_contexts_scores = reduced_dim_retreival(np_embeddings, original_query_embeddings, test_case, sm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjnEuetzRnoN"
      },
      "outputs": [],
      "source": [
        "cosine_contexts_scores = get_cosine_context(original_query_embeddings, docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUjU9u0NVWAk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49uBWJhlVWD_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLjecNHYVWHC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKepSgo9VWJ9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dibeF5rmMSZu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "def create_context_dataframe(questions, answers, all_som_contexts, all_cosine_contexts):\n",
        "  df = pd.DataFrame({\n",
        "      \"question\": questions,\n",
        "      \"answer\": answers,\n",
        "      \"som_context\": all_som_contexts,\n",
        "      \"cosine_context\": all_cosine_contexts,\n",
        "  })\n",
        "  return df\n",
        "\n",
        "def save_and_download_context(df, filename=\"wikipedia_context_comparison.csv\"):\n",
        "  df.to_csv(filename, index=False)\n",
        "  files.download(filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5P2U-H1VA6n"
      },
      "source": [
        "# ! Download results to local storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "b7362800",
        "outputId": "8628c75d-01e5-4445-a0a3-1a3ff680a435"
      },
      "outputs": [],
      "source": [
        "df = create_context_dataframe(questions, answers, som_contexts_scores, cosine_contexts_scores)\n",
        "save_and_download_context(df, \"wikipedia_context_comparison.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfmycBYEnuS5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vijtmit-aX_A"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9sL8JljaYCH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEy0BgpoaYFX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_HEK-f0aYIo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceeqbGrKaYLp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ax744HA7aYPQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WwoSqsYdEld"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBNHI2hFdFlT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFro26TCdFil"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBvzR4sCdGB0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "evaluation_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ce14b200cb3482b82ac55e763c51c3f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a588cc017224523bfae706ac82e3d9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1f3ed85a4894637a22954ab9798409c",
              "IPY_MODEL_751f988c52cd4429b910c505520cdb6f",
              "IPY_MODEL_6c339ae65bec4ffcad7ed7e5341bea45"
            ],
            "layout": "IPY_MODEL_b1ae6800a5f64addbde168c1c3a6f069"
          }
        },
        "1c24fbe824514792b73fbab0129eb13e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "244c48b08395443886c2bad51b6dfeae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "2a4ce798bca7432f881932fff7ee9def": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cdc61c36367459a8b52e9991e18e6f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_244c48b08395443886c2bad51b6dfeae",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c24fbe824514792b73fbab0129eb13e",
            "value": 1
          }
        },
        "45ee321cd90d488bb3b3e3c06a8d2ce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4aa829263c6740069462a72452650c4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "674066dbd3d1469aa40e98331a678823": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab512cdfc65347659b66b2c974664e96",
              "IPY_MODEL_2cdc61c36367459a8b52e9991e18e6f2",
              "IPY_MODEL_e6c506ecf1084230b25e4b63af492a73"
            ],
            "layout": "IPY_MODEL_eb0edcf7d43e49ceaf7f4dd550f3eb4b"
          }
        },
        "6c339ae65bec4ffcad7ed7e5341bea45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3fff85d33e54ef9b80ddaf2926f3f77",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_dcb75619b1454898a585397bd48ea5d0",
            "value": "â€‡3.84k/?â€‡[00:00&lt;00:00,â€‡63.0kB/s]"
          }
        },
        "751f988c52cd4429b910c505520cdb6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b89dde531464cf98678cfff8b7ee85c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1e900d644d24a128218f56708e732e5",
            "value": 1
          }
        },
        "9b89dde531464cf98678cfff8b7ee85c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "9cd0a8b9d7444169a55708ab431fc023": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab512cdfc65347659b66b2c974664e96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cd0a8b9d7444169a55708ab431fc023",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4aa829263c6740069462a72452650c4a",
            "value": "dataset_infos.json:â€‡"
          }
        },
        "b1ae6800a5f64addbde168c1c3a6f069": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcb75619b1454898a585397bd48ea5d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1e900d644d24a128218f56708e732e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e1f3ed85a4894637a22954ab9798409c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ce14b200cb3482b82ac55e763c51c3f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_45ee321cd90d488bb3b3e3c06a8d2ce8",
            "value": "README.md:â€‡"
          }
        },
        "e6c506ecf1084230b25e4b63af492a73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8c112acbbbd4d198e93f4cc449a8b24",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2a4ce798bca7432f881932fff7ee9def",
            "value": "â€‡1.29k/?â€‡[00:00&lt;00:00,â€‡23.7kB/s]"
          }
        },
        "e8c112acbbbd4d198e93f4cc449a8b24": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb0edcf7d43e49ceaf7f4dd550f3eb4b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3fff85d33e54ef9b80ddaf2926f3f77": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
